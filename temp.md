\section{Introduction}

Ethereum and other EVM-compatible blockchains rely on general-purpose virtual machines to execute smart contracts. As transaction throughput and contract complexity increase, execution becomes a primary scalability bottleneck for both full and archive nodes. While consensus and data availability layers have scaled significantly, the sequential execution of complex smart contracts remains a limiting factor for network performance.

To address this bottleneck, recent research has explored various optimization strategies, ranging from Just-In-Time (JIT) compilation to path-driven speculative execution. Systems such as Forerunner and Seer record detailed transaction-level traces or maintain substantial shadow state to guide speculative reuse, while EVMTracer and ParallelEVM exploit operation-level parallelism. However, these approaches face an inherent trade-off when applied to modern, highly optimized EVM interpreters such as Revm. We refer to this trade-off as a \textit{performance paradox}: when the baseline EVM is already highly optimized, the overhead of tracing, analysis, and artifact management can outweigh the benefits of optimization. Contract-driven JIT approaches, while theoretically powerful, introduce security risks such as JIT bombs and complicate the maintenance of gas-semantic equivalence. Conversely, traditional path-driven approaches incur significant memory I/O and analysis overhead. On fast interpreters where baseline execution completes in microseconds, the cost of loading and processing large trace artifacts often exceeds the execution time itself.

This challenge necessitates a path-driven execution engine that remains safe and gas-precise, yet lightweight enough to deliver net gains on top of modern EVM interpreters. A key observation is that existing systems operate at a suboptimal granularity. Transaction-level caching fails to exploit the repetition of individual contract calls across different transactions, while full-state tracing captures far more information than is necessary for effective optimization.

In this paper, we present Helios, a lightweight, path-driven execution engine designed for high-performance EVM clients. Helios addresses the performance paradox through three core design principles. First, it employs \textit{lightweight asynchronous tracing} that records only stack operations and minimal data dependencies, avoiding the overhead of shadowing full EVM state. This tracing runs off the critical path, so that optimization does not delay live execution. Second, Helios implements \textit{frame-level caching}. We observe that call frames exhibit strong path locality across transactions, so that a relatively small set of cached paths can cover a large fraction of execution. By caching optimized paths at the frame level rather than the transaction level, Helios achieves effective reuse with modest storage overhead. Third, by restricting optimizations to static-cost instructions and delegating all dynamic-cost operations to the underlying EVM, Helios preserves gas semantics by construction, without requiring complex compensation logic.

Helios operates in two distinct modes to support diverse node workloads. In \textit{Replay Mode}, targeted at archive nodes, it leverages pre-computed paths to accelerate historical block processing with no speculation overhead. In \textit{Online Mode}, targeted at full nodes, it employs a simple frequency-based mechanism to speculatively optimize hot paths in real time while falling back to the native interpreter on mispredictions.

We make the following contributions:

\begin{itemize}
    \item \textbf{Problem Analysis and Design Insight.} We analyze why existing JIT- and trace-based EVM optimizers struggle to deliver net gains on top of modern interpreters, and identify frame-level reuse with lightweight tracing as a viable design point. We show that a small fraction of frame-level paths accounts for the majority of execution time on mainnet workloads.
    \item \textbf{System Design.} We design and implement Helios, an execution engine that decouples tracing, optimization, and execution. Our architecture integrates with existing EVM clients, leveraging their native state management while accelerating computational logic through an SSA-based optimizer.
    \item \textbf{Evaluation.} We evaluate Helios on Ethereum mainnet workloads. In Replay Mode, Helios achieves a median speedup of 6.60$\times$ over the baseline Revm interpreter. In Online Mode, a frequency-based filter yields net speedups on hot blocks while keeping the storage footprint in the kilobyte range per contract. Our SSA optimizer eliminates a large fraction of stack and arithmetic instructions on hot paths, which contributes to these throughput gains.
\end{itemize}

The rest of this paper is organized as follows. We provide background on EVM execution and prior optimization approaches in \S\ref{sec:background}, then motivate the design of Helios in \S\ref{sec:motivation}. We present the system design in \S\ref{sec:design}, evaluate Helios on microbenchmarks and mainnet workloads in \S\ref{sec:evaluation}, and discuss implications and future directions in \S\ref{sec:discussion}.

\section{Background}
This section provides the necessary background of the blockchain execution environment. We briefly introduce the core execution model of the Ethereum Virtual Machine (EVM), its resource metering mechanism known as Gas, and the distinct node workloads that motivate the dual-mode design of Helios.

\subsection{The Ethereum Virtual Machine (EVM) Execution Model}
The EVM is a quasi-Turing-complete, stack-based virtual machine that serves as the sandboxed execution environment for smart contracts on the Ethereum blockchain. Its architecture and state model impose specific constraints and present unique opportunities for optimization, which directly inform the design of Helios. The overall execution workflow, depicted in Figure~\ref{fig:evm-workflow}, is partitioned into a high-level frame management lifecycle and a low-level, per-opcode execution loop. The following subsections detail the key components of this model.

\subsubsection{Stack-Based Architecture}
The EVM operates on a shared, 1024-element deep runtime stack where each element is a 256-bit word. All computational opcodes retrieve their operands by popping from the top of the stack and push their results back onto it. This model contrasts with traditional register-based architectures that operate on named registers via direct addressing. While conceptually simple, the stack-based design necessitates a high frequency of explicit stack manipulation instructions to manage data flow. These instructions, alongside the overhead of indirect memory access through a stack pointer, represent a primary target for optimization in Helios.

As illustrated in the in-frame execution loop of Figure~\ref{fig:evm-workflow}, every operation interacts with this per-frame runtime stack. Stack manipulation instructions, such as DUP1-DUP16 for duplicating items at various depths and SWAP1-SWAP16 for swapping the top element with items at different positions, are prevalent in EVM bytecode as compiler-generated boilerplate for managing operand placement. Unlike computational opcodes, these instructions rearrange existing stack elements without producing new values, making them particularly amenable to elimination.

\subsubsection{State Model: Volatile Memory and Persistent Storage}
The EVM maintains two distinct data storage mechanisms: transient memory and persistent storage, visually represented in Figure~\ref{fig:evm-workflow} as Shared Memory and Journaled State respectively. Memory is a byte-addressable linear array with transaction-scoped lifetime, utilized for ephemeral data such as function call arguments and intermediate computation buffers. Storage, by contrast, implements a persistent key-value mapping from 256-bit keys to 256-bit values, constituting the contract's global state that persists across transaction boundaries. Operations on storage are computationally more expensive than memory operations due to their impact on the global state.

The modification of memory and storage constitutes an observable side effect. This characteristic constrains compiler optimizations, as operations with such side effects cannot be reordered or eliminated without altering program semantics. Consequently, Helios focuses its most aggressive optimizations on the computational, side-effect-free operations that occur between state interactions.

\subsubsection{Call Frames}
EVM execution is organized into a hierarchy of call frames. The lifecycle of a single frame, from its creation to its finalization, is depicted in the workflow on the left side of Figure~\ref{fig:evm-workflow}. A new frame, with its own independent memory and runtime stack, is created for each function call, including external calls between different smart contracts. All frames within a single transaction, however, share access to the same persistent storage. A transaction's execution can thus be modeled as an ordered sequence of these call frames. 

\subsubsection{Hook Mechanism}
The EVM specification includes a standard hook mechanism to support native tracers and debuggers. This interface allows an external component to subscribe to events that are triggered immediately before and after the execution of each opcode, as well as at the entry and exit points of every call frame, which are explicitly marked as Hook Events in Figure~\ref{fig:evm-workflow}. This standard, non-invasive interface is foundational for any external profiling tool, as it enables the passive observation of an execution without modifying the core EVM interpreter.

\subsection{Gas: The Resource Metering Mechanism}
\label{sec:gas}
Gas is the fundamental mechanism in the EVM for metering computational resource consumption. It serves both to incentivize validators for the computational work they perform and to protect the network from denial-of-service attacks by ensuring that all executed operations are paid for.

Every transaction submitted to the network must specify a gas limit, representing the maximum amount of gas the originator is willing to consume. Each opcode executed by the EVM deducts a specific amount of gas from this limit. If the total gas consumed exceeds the limit at any point, the execution is halted, an out-of-gas (OOG) exception is raised, and all state changes made by the transaction are reverted. This mechanism ensures that even programs with infinite loops will eventually terminate, making the otherwise Turing-complete EVM a quasi-Turing-complete machine.

EVM gas costs can be categorized into two types: static and dynamic. Static costs are fixed, compile-time determinable values. The majority of opcodes, such as those for arithmetic or logical operations, have a low, constant gas cost. Dynamic costs are values that depend on the runtime state of the EVM. Examples include the cost of expanding memory, which is a quadratic function of the current memory size, or the cost of an SSTORE operation, which depends on whether a storage slot is being accessed for the first time in the transaction or has been accessed before.

This distinction is central to performance optimization, as it creates the opportunity to aggregate and pre-calculate the cumulative static gas costs of long instruction sequences. Dynamic costs, in contrast, must be calculated at runtime to ensure semantic equivalence.

Certain opcodes, termed gas delimiters, explicitly interact with the gas counter. On healthy execution paths where no out-of-gas exception occurs, these delimiters represent the only points where the gas balance must be observable. GAS reads the current gas balance onto the stack; RETURN, STOP, and REVERT finalize frame execution and require gas verification; CREATE and CREATE2 allocate gas to child contracts. These delimiters partition execution into segments, enabling bulk gas deduction for intervening operations.

\subsection{Node Types of the Ethereum Network}
The dual-mode design of Helios is a direct response to the distinct operational requirements and workload characteristics of the two primary types of nodes in the Ethereum network: Full Nodes and Archive Nodes.

A full node is responsible for participating in the real-time operation of the network. Its primary tasks include receiving new transactions from the peer-to-peer network, executing and validating them, and including them in new blocks. This workload is latency-sensitive, as block production times are fixed. Furthermore, full nodes must process transactions with limited predictability, as they frequently encounter novel smart contracts and previously unseen execution paths. This environment, characterized by low latency requirements and high uncertainty, motivates the need for an execution strategy that can perform on-demand, adaptive optimization as new transactions are observed.

An archive node stores the complete history of the blockchain's state from the genesis block to the present. Its primary workload involves serving historical data queries and, crucially, re-executing large batches of historical blocks, for instance, to sync a new node or for data analysis purposes. This workload is throughput-sensitive, prioritizing the total time to process millions of known, historical transactions over the latency of any single one. The execution is entirely deterministic, as the inputs and outcomes of all historical transactions are already recorded on the blockchain. This high-throughput, deterministic workload motivates the need for a specialized execution strategy that can leverage pre-computed knowledge of historical executions to achieve maximum speed with zero speculation overhead.

\subsection{Foundational Concepts in Code Optimization}
The design of Helios's SSA Optimizer is informed by foundational concepts from the field of compiler theory. A key concept is Static Single Assignment (SSA), an intermediate representation property where each variable is assigned a value exactly once. This property makes data dependencies explicit and simplifies a wide range of optimizations. An execution trace that assigns a unique identifier (e.g., a sequence number) to the result of every operation naturally produces an SSA-like representation. Additionally, the EVM ecosystem presents a clear opportunity for a caching system to implement a code/data separation strategy. Contract standards like ERC-20 result in thousands of deployed instances that share identical logic but differ only in their initial constant values, such as a token's name or total supply. With this background on the EVM's architecture, its resource metering model, and the operational context of blockchain nodes, we now proceed to motivate the design of Helios, addressing the limitations of existing approaches.

\subsection{Prior EVM Optimization Approaches}
Recent systems have explored path-driven optimization strategies to accelerate EVM execution. Forerunner employs constraint-based speculative execution, pre-executing transactions in the transaction pool and generating optimized fast-path programs guarded by control-flow and data-dependency constraints. Seer introduces fine-grained branch prediction with checkpoint-based snapshots to maximize pre-execution result reuse across different execution paths. ParallelEVM achieves operation-level concurrent transaction execution through SSA-based conflict detection and selective re-execution of conflicting operations. EVMTracer provides dynamic analysis tools to construct opcode-level dependency graphs for quantifying parallelization potential and computational redundancy.

These systems employ comprehensive tracing mechanisms that capture complete execution state, including stack operations, memory accesses, and storage dependencies, enabling detailed analysis and optimization of execution paths across EVM-compatible blockchain systems.

\section{Motivation}

Traditional path-driven optimization systems like Forerunner and Seer achieve 5–8× speedups on classical EVM interpreters such as Geth. However, when applied to modern, highly-optimized implementations like Revm, these gains diminish sharply. For identical bytecode, speedups drop from 5.0× on Geth to only 1.5× on Revm. This degradation exposes fundamental limitations in existing optimization strategies when baseline execution is already fast. Through systematic analysis across four critical design dimensions of optimization paradigm, tracing strategy, artifact organization, and correctness guarantees, we derive a set of principled design choices that enable effective optimization on modern EVMs. Each choice addresses specific bottlenecks while establishing constraints that guide subsequent decisions, ultimately converging on Helios's architecture.

\subsection{Path-Driven over Contract-Driven Optimization}

EVM optimization can follow two competing paradigms. Contract-driven optimization, exemplified by JIT compilation approaches, optimizes entire contracts. Path-driven optimization, employed by systems like Forerunner and Seer, optimizes only executed traces. This foundational choice establishes the scope and safety model for all subsequent design decisions.

Contract-driven approaches compile entire contract bytecode into optimized native code, enabling aggressive global optimizations such as loop hoisting, dead code elimination, and cross-basic-block register allocation. These transformations can yield substantial performance improvements on hot contracts. However, this paradigm faces two critical challenges in production blockchain environments.

First, unrestricted JIT compilation introduces severe security risks through JIT Bomb attacks. Malicious bytecode can exploit compilation complexity by using deeply nested control flow or pathological loop structures to force the JIT compiler into exponential-time compilation or excessive memory consumption. This denial-of-service vector is particularly dangerous in blockchain contexts where attackers can trivially deploy adversarial contracts and force validators to compile them. Existing JIT-based EVM implementations address this threat through contract whitelisting, restricting optimization to pre-approved contracts. This mitigation severely limits applicability, as the majority of contract invocations fall outside whitelists, rendering the optimization ineffective for general workloads.

Second, aggressive global optimizations frequently violate gas-semantic equivalence. Figure~\ref{fig:loop-hoisting-gas} illustrates this problem through a representative example where loop hoisting reduces the number of storage reads, thereby changing the gas consumption profile. While this transformation improves performance, it creates economic misalignment between charged fees and actual resource usage. This divergence presents validators with an undesirable choice between overcompensating for work performed or undercompensating relative to network standards, potentially discouraging adoption of the optimization.

Path-driven optimization offers a different trade-off. By optimizing only actually-executed paths rather than entire contracts, this paradigm inherently bounds optimization costs per path, eliminating JIT Bomb vulnerabilities. Every path processed represents real execution that already occurred, ensuring compilation work scales linearly with actual usage rather than potential attack surface. This enables universal deployment without whitelists. Any contract invoking frequently-executed paths automatically benefits from optimization, regardless of bytecode complexity or origin.

However, path-driven systems must still address gas-semantic preservation explicitly. While this paradigm avoids the cross-contract global optimizations that complicate gas preservation in JIT approaches, it does not automatically guarantee gas equivalence. Existing path-driven systems such as Forerunner and Seer do not explicitly discuss this equivalence in their design. Helios achieves precise gas-semantic preservation through specific design choices, particularly the combination of stack-only tracing, frame-level organization, and path-local transformations, as we will demonstrate in \S\ref{sec:gas-semantic-equivalence}.

The choice of path-driven optimization establishes our first architectural constraint. We optimize execution traces post-facto rather than contracts a priori. This decision prioritizes safety and universal applicability over maximal theoretical performance, setting the foundation for subsequent design choices.

\subsection{The Overhead of Existing Path-Driven Approaches}
Having established the path-driven paradigm, we now examine why existing implementations struggle on modern EVMs. The core issue is a performance paradox. Detailed tracing, once a minor cost on slow interpreters, becomes the primary bottleneck when baseline execution is already fast.

This paradox manifests most severely in the memory I/O cost of optimization artifacts. Table~\ref{tab:motivation-overhead} demonstrates this performance degradation through measurements on a representative Uniswap V2 single-hop swap. Forerunner achieves substantial speedups on Geth but experiences diminished returns on Revm despite generating identical 663 KB trace artifacts. We note that since Forerunner does not provide a native Revm implementation, our measurements employ a functionally equivalent mock implementation that replicates Forerunner's tracing and optimization strategy on the Revm runtime. The reduced baseline execution time on modern EVMs exposes artifact overhead as the dominant bottleneck. When baseline execution completes in tens of microseconds, loading and parsing trace artifacts of this magnitude consumes time comparable to the computational work being optimized.

However, artifact I/O represents only part of the overhead. Full-tracing approaches that maintain custom execution context management—including call frames, memory snapshots, and storage deltas—forgo the host EVM's optimized native implementations. For complex transactions with artifacts exceeding hundreds of kilobytes, I/O latency dominates. For simple transactions such as ERC20 transfers, where artifact sizes remain modest, the computational cost of redundant context management becomes the primary bottleneck. Modern EVMs provide highly optimized frame-level infrastructure. An effective strategy must leverage these mechanisms rather than duplicating them.

Tracing itself also introduces computational overhead. Existing systems employ different strategies to mitigate this cost. Forerunner and Seer perform tracing in the transaction pool, asynchronously profiling pending transactions before block execution. This removes tracing from the critical path, though artifact I/O costs remain during actual execution. ParallelEVM performs online tracing during parallel execution, where each thread simultaneously executes and traces transactions before resolving conflicts through selective re-execution. This strategy reduces memory I/O by avoiding large pre-generated artifacts and relying instead on runtime dependency tracking.

However, on modern EVMs like Revm, both strategies become prohibitively expensive. We instrumented Revm with a comprehensive tracer recording stack, memory, and storage dependencies during execution. Single-transaction latency increased from 60 µs to over 300 µs, representing a 5× slowdown on the critical path. This overhead stems from per-opcode hook invocations, shadow data structure maintenance, and context switches between the EVM engine and tracing infrastructure. When baseline execution operates at this speed, these mechanisms consume time comparable to the operations being traced.

Furthermore, the purported advantage of full dependency tracking proves illusory in practice. EVMTracer proposed exploiting opcode-level dependencies to parallelize execution within a single transaction. We implemented a dependency-graph-driven parallel executor for Revm that schedules independent opcodes across multiple threads based on recorded dependencies. Contrary to theoretical models, the parallel version consistently underperformed its optimized serial counterpart. The root cause is fundamental. At nanosecond execution granularity, thread synchronization and communication overhead far exceeds the time saved by parallel instruction execution. When individual opcodes complete in 20 nanoseconds but thread coordination requires hundreds of nanoseconds, parallelism merely adds overhead.

\noindent\textbf{Design Principle 1.} \emph{Minimize analysis overhead through lightweight, asynchronous tracing that leverages host EVM infrastructure.} To achieve meaningful speedups on modern EVMs, an optimization strategy must produce compact artifacts to minimize I/O costs, operate asynchronously off the critical execution path, reuse the host EVM's optimized frame management and state access mechanisms, and capture only information that enables practical, low-overhead optimizations.

This principle establishes the next constraint. Any tracing mechanism must be selective, focusing on the subset of execution state that yields the highest optimization return per byte of trace data. The question then becomes what subset of execution dependencies we should capture.

\subsection{Frame-Level Reuse over Monolithic Traces}
\label{sec:frame-level-caching}

The previous section established the need for lightweight tracing. However, reducing tracing overhead alone is insufficient. We must also maximize the value extracted from each traced execution. This requires addressing two interrelated design decisions regarding the granularity of optimization artifacts and the mechanisms for enabling their reuse across transactions.

Existing path-driven systems adopt transaction-level artifact organization, where each transaction's optimization artifacts are generated and discarded immediately after use. This granularity choice introduces severe limitations for reuse. Consider three transactions where Tx1 calls contracts C1→C2, Tx2 calls C3→C4, and Tx3 calls C1→C3. Under transaction-level organization, Tx3 cannot reuse cached artifacts from Tx1 or Tx2, despite sharing individual contract call frames. The cache key is the entire transaction's execution pattern, the specific sequence C1→C3, rather than individual frame paths. Even though the C1 invocation in Tx3 may be identical to the C1 invocation in Tx1, and the C3 invocation identical to that in Tx2, the system is forced to retrace both frames because the transaction-level composition is novel. This use-once-discard model represents significant wasted effort. Even when constituent frames execute along identical paths, the system repeats the full tracing and optimization process.

Frame-level organization resolves this limitation by treating each contract call frame as an independent optimization unit. In the Tx3 example, the individual C1 frame can be recognized and reused from Tx1's cache, and the C3 frame from Tx2's cache. Only genuinely novel frame-level execution patterns require new tracing. This compositional reuse substantially increases effective cache coverage. Rather than requiring exact transaction-level matches, the system benefits from any partial overlap in the frame-level call graph.

To validate this design choice and quantify the economic value of frame-level caching, we conducted large-scale path analysis on Ethereum mainnet blocks 19,600,000 through 19,605,000. For each contract call frame, we compute a path identifier by hashing the sequence of executed opcodes within that frame, then track the frequency distribution of these unique path identifiers across all frames in the analyzed blocks.

The results in Figure~\ref{fig:pareto-cumulative} reveal a pronounced Pareto distribution with strong path locality. The top 10\% of unique paths account for over 90\% of all frame executions. Further decomposition shows extreme concentration. The top 1\% of paths handle 70\% of executions, and the top 5\% handle 85\%. This distribution remains stable across different block ranges and time periods, indicating that path locality is a fundamental characteristic of EVM execution rather than transient behavior.

This empirical finding confirms the value of persistent, frame-level caching. For high-frequency paths in the top 1\%, a single tracing cost can be amortized across hundreds or thousands of subsequent executions. When a path appears 1000 times but requires tracing only once, the effective per-execution overhead becomes negligible, fundamentally changing the cost-benefit ratio compared to transaction-level use-once-discard approaches. The extreme concentration further suggests that even modest cache sizes can achieve high hit rates by retaining only the most frequently executed paths.

Furthermore, frame-level granularity aligns naturally with the EVM's execution model, which inherently manages resources and state at frame boundaries. Each call frame operates within an isolated context with its own memory space, storage view, and gas quota. This alignment allows direct reuse of mature frame management infrastructure from host EVM clients, including optimized memory allocation and storage access patterns. Transaction-level approaches, by contrast, must implement custom frame simulation logic to maintain correctness across artificially flattened execution sequences, adding complexity and potential correctness risks.

The combination of empirical path locality and architectural alignment motivates our second principle.

\noindent\textbf{Design Principle 2.} \emph{Enable cross-transaction reuse through frame-level, persistent caching.} Optimization artifacts should be organized at the frame granularity and indexed by per-frame path identifiers. This enables compositional reuse across transactions, amortizes optimization costs across high-frequency paths, and leverages host EVM infrastructure for frame management.

This principle establishes two additional constraints. First, artifact organization must respect frame boundaries. Second, caching must support persistent storage with efficient lookup. These constraints, combined with the lightweight tracing requirement from Principle 1, narrow the design space considerably. The remaining question is what specific execution information we should trace and optimize.

\subsection{Achieving Natural Gas-Semantic Equivalence}
\label{sec:gas-semantic-equivalence}

The previous sections established the need for lightweight, frame-level, path-driven optimization. However, any optimization strategy must ultimately satisfy a critical correctness requirement specific to blockchain execution. Exact preservation of gas semantics is essential because gas underpins miner incentives in Ethereum's economic model. Transaction senders pay fees proportional to gas consumed. Any optimization altering gas consumption disrupts this economic balance, either overcompensating miners when charging original gas for reduced work or undercompensating them when charging reduced gas. Maintaining gas-semantic equivalence, defined as exact matching of native execution's gas accounting, is thus an economic necessity for practical adoption.

The core challenge stems from the distinction between static-cost and dynamic-cost instructions as defined in \S\ref{sec:gas}. Static-cost instructions have compile-time-determinable gas costs, while dynamic-cost instructions have runtime-dependent costs that depend on state such as memory expansion or storage access history.

Any optimization that eliminates or reorders dynamic-cost instructions risks gas divergence, as demonstrated in \S\ref{sec:path-vs-contract} with loop hoisting. However, if we restrict optimization to static-cost instructions only, gas preservation becomes straightforward. We precompute the cumulative gas of eliminated operations and deduct it in bulk, while ensuring all dynamic-cost instructions execute natively with precise accounting.

Remarkably, our previous design decisions, driven by entirely orthogonal concerns, naturally converge to enable this strategy. First, lightweight tracing from Principle 1 led us to focus on operations with low tracing overhead while excluding those requiring substantial state tracking. This scope restriction carries an important secondary consequence. Operations excluded due to tracing cost are precisely those with dynamic gas pricing, such as memory expansion and storage access history, while the traced operations are precisely those with static costs. The excluded instructions also share a common characteristic. They perform side effects on persistent or expandable state, making their costs inherently runtime-dependent. In contrast, the included instructions operate solely on the evaluation stack, a fixed-size structure whose manipulation incurs predictable, compile-time-determinable costs.

Second, frame-level granularity from Principle 2 aligns optimization boundaries with the EVM's native gas accounting boundaries, as each call frame independently tracks gas consumption. Third, the path-driven paradigm from \S\ref{sec:path-vs-contract} constrains optimization to path-local transformations, avoiding cross-basic-block optimizations that would complicate gas accounting across control flow.

The convergence of these three orthogonal choices produces an elegant emergent property. Lightweight tracing naturally selects static-cost operations, frame-level organization aligns with gas boundaries, and path-driven optimization constrains transformations. Together, the optimization scope naturally excludes all dynamic-cost, side-effecting instructions, enabling gas-semantic equivalence without compensatory mechanisms. Each decision, motivated by distinct concerns of overhead reduction, reuse efficiency, and security, contributes guarantees that combine to solve the correctness problem. This is not a coincidence requiring delicate engineering but a robust consequence of constraint composition.

This convergence motivates our third principle.

\noindent\textbf{Design Principle 3.} \emph{Achieve gas-semantic equivalence as an emergent property of design constraints.} By restricting optimization to static-cost instructions through stack-only tracing, aligning artifact boundaries with gas accounting boundaries through frame-level organization, and constraining transformations through path-driven optimization, gas preservation arises naturally. The system can freely optimize within this scope without trading off performance against correctness.

\subsection{Synthesis: Deriving the Helios Architecture}
\label{sec:synthesis}

The three design principles of lightweight asynchronous tracing, frame-level persistent caching, and emergent gas-semantic equivalence map to Helios's architectural components with varying directness. The first two principles directly drive core components, while the third principle emerges as a natural consequence of their interaction.

Principle 1 manifests in three functional requirements. First, a selective tracer must capture execution dependencies with minimal overhead, generating compact artifacts approximately one order of magnitude smaller than full traces. Second, an asynchronous processing pipeline must decouple tracing from execution, processing artifacts off the critical path through background threads to eliminate online overhead while maintaining low artifact availability latency. Third, the tracing mechanism must leverage the host EVM's optimized native infrastructure for frame management and state access.

Principle 2 necessitates a persistent caching mechanism with per-frame-path indexing. The cache must support both deterministic lookup for known path identifiers and speculative querying for predicted hot paths. Persistent storage enables cross-transaction amortization. High-frequency paths in the top 1\% incur tracing costs once but benefit thousands of subsequent executions. Frame-level granularity enables compositional reuse, as demonstrated in \S\ref{sec:frame-level-caching}, substantially increasing effective cache coverage compared to transaction-level approaches.

An efficient execution engine is required to consume cached artifacts and accelerate hot path execution. This engine must translate traced execution sequences into an optimized execution model while preserving correctness. Principle 3 constrains the optimization scope to naturally exclude dynamic-cost operations, enabling a straightforward gas accounting strategy. The system precomputes cumulative static gas for optimized operations and deducts it in bulk at frame entry, while delegating all excluded dynamic-cost operations to the native mechanism. This design achieves exact gas equivalence without runtime compensation logic or gas recalculation overhead.

These components support two operational modes addressing distinct node workloads. Replay Mode targets archive nodes performing deterministic historical synchronization. Since all execution paths are known and unchanging, the cache can be pre-populated through one-time tracing of the entire blockchain history. Subsequent replays achieve complete cache coverage, amortizing single tracing costs across thousands of re-executions and enabling substantial speedups with minimal storage overhead, making historical replay economically viable for resource-constrained archive nodes.

Online Mode addresses full nodes processing unpredictable live transactions. Background tracing captures new paths without blocking execution per Principle 1. Dynamic caching maintains coverage of hot paths while evicting cold ones under memory pressure per Principle 2. When a cached path is available, the system executes it optimistically. On cache misses or validation failures, execution falls back to native interpretation, ensuring correctness for never-before-seen patterns.

Critically, both modes share identical core components and artifact formats, differing only in cache population strategy and execution strategy. Pre-fill versus on-demand caching distinguishes Replay Mode from Online Mode, as does deterministic versus speculative execution. This unified design allows a single implementation to span the full node-type spectrum. Quantitative performance evaluation, including detailed speedup measurements, cache hit rates, and storage overhead analysis for both operational modes across diverse workloads, is presented in Section~\ref{sec:evaluation}.

Building on these three design principles and their instantiation across operational scenarios, the following section presents Helios's detailed architecture.

\section{The Design of Helios}

\subsection{Overview}
Helios is a path-driven execution engine designed to accelerate Ethereum Virtual Machine (EVM) transaction processing. Its architecture is built on a continuous feedback loop that integrates four coordinated components: the Path Tracer, the SSA Optimizer, the Path Cache, and the Helios Engine. Notably, path tracing and optimization are performed asynchronously, running in parallel with the primary transaction execution flow. Figure 1 illustrates the system's high-level architecture and data flow. This asynchronous design eliminates optimization latency from the critical path, ensuring that trace generation and graph compilation do not delay transaction processing.

The system's functionality is partitioned across these four distinct components. The Path Tracer captures raw execution traces through lightweight, hook-based instrumentation of the native EVM interpreter, producing a linear execution record known as a PathLog. The SSA Optimizer transforms these PathLog entries into an SSA-like intermediate representation, termed SsaGraph, by applying a pipeline of classic compiler optimizations to eliminate redundant computations. The Path Cache serves as an in-memory memoization layer, indexing and storing optimized SsaGraph structures for rapid, low-latency retrieval. Finally, the Helios Engine orchestrates the execution of each transaction, determining whether to use a cached SsaGraph for accelerated processing or to delegate the task to the native interpreter as a fallback. 

\subsection{End-to-End Transaction Lifecycle}
The Helios architecture supports two distinct operational modes---Online and Replay---each defining a different transaction processing lifecycle. The Online mode is designed for real-time processing where execution paths are unknown, while the Replay mode is optimized for high-throughput batch processing of historical transactions with pre-determined paths. 

\subsubsection{Online Mode: Executing New Transactions}
Online mode is engineered for the real-time processing demands of full nodes and validators, where execution paths are often unknown. When a function is invoked, the Helios Engine generates an identifier based on the contract and the function being called. It uses this identifier to query the Path Cache for a corresponding SsaGraph. If a matching path is found, the Traced Interpreter begins speculative execution, validated at runtime by control-flow guards. A guard failure or a cache miss triggers an immediate, transaction-level fallback to the Native Interpreter, which executes the transaction to completion to ensure correctness.

This fallback event activates the asynchronous optimization pipeline. The Path Tracer observes the native execution and generates a detailed, linear trace of the operations performed. This trace is then dispatched to the SSA Optimizer, which transforms it into an optimized SsaGraph and its associated constant data. Finally, these new artifacts are stored in the Path Cache, populating it for subsequent executions.

\subsubsection{Replay Mode: Executing Historical Transactions}
Replay mode is tailored for the high-throughput batch processing requirements of archive nodes. In this mode, transaction execution is deterministic. Before processing, the Helios Engine retrieves a pre-computed plan for the transaction, which contains an ordered list of unique identifiers for each execution path. For each frame, the engine uses the corresponding path identifier to perform a direct lookup in the Path Cache.

This lookup is guaranteed to succeed, as the plan only references paths that were successfully traced and cached during a prior execution. The Path Cache returns the precise SsaGraph and its associated constant data. The Traced Interpreter then executes this path directly. In this mode, the speculative nature of the Online mode is entirely eliminated as there are neither cache misses nor control-flow guards needed, and the asynchronous tracing and optimization pipeline is bypassed. This streamlined process enables maximum execution throughput for reprocessing historical blocks.

\subsection{Key Data Structures}
Helios uses a set of data structures to represent, index, and orchestrate the execution of transaction paths. These abstractions manage the system's data flow, enabling both the speculative execution of Online mode and the deterministic processing of Replay mode.

\subsubsection{Path Representation}
Execution paths are captured and optimized through two primary representations:

\begin{itemize}[leftmargin=0pt, itemindent=0pt, labelwidth=1em, labelsep=0.5em]

\item \textbf{PathLog}: A raw, linear record of an execution path generated by the Path Tracer. It contains a sequence of entries, where each entry details a single operation's opcode and its stack data dependencies, recorded as references to the outputs of prior operations. The PathLog serves as the direct input to the optimization pipeline.

\item \textbf{SsaGraph}: The optimized, graph-based representation of an execution path. It is a directed acyclic graph where nodes represent operations and edges represent data dependencies. This structure makes data dependencies explicit, removing the need for a runtime stack machine and serving as the executable format for the Traced Interpreter.

\end{itemize}

\subsubsection{Path Indexing and Retrieval}
To locate and reuse SsaGraph structures, Helios employs a multi-key indexing scheme:

\begin{itemize}[leftmargin=0pt, itemindent=0pt, labelwidth=1em, labelsep=0.5em]

\item \textbf{PathDigest}: A 64-bit hash of a path's opcode sequence. It serves as a unique and compact identifier for a specific execution path. Its primary use is for deterministic lookups in the Path Cache.

\item \textbf{DataKey}: A composite key created by concatenating a contract's code hash with a PathDigest. It is used to index the constant table associated with a specific path in a specific contract instance. This key is necessary to enable a code/data separation strategy. For instance, two different ERC20 token contracts deployed from identical source code will share the same PathDigest for a transfer call. However, their bytecodes may contain different immediate values, such as those encoding the token name or total supply. The DataKey ensures that while they can reuse the same SsaGraph structure, the system retrieves the correct, contract-specific constant table for each.

\item \textbf{CallSig}: A coarse-grained identifier used for predictive path lookups in Online mode. It is generated by concatenating a contract's code hash with the 4-byte function selector from the transaction's calldata. A single CallSig can map to multiple PathDigests, each representing a distinct control-flow branch that a function invocation may follow, including both successful execution and revert paths.

\end{itemize}

\subsubsection{Execution Metadata}
Helios captures additional metadata to manage cross-frame execution and optimize performance:

\begin{itemize}[leftmargin=0pt, itemindent=0pt, labelwidth=1em, labelsep=0.5em]

\item \textbf{Transaction Plan (TxPlan)}: An ordered sequence of PathDigests that records the execution path taken by every function frame within a single transaction. TxPlans are generated during Online mode execution and indexed by block number and transaction index. In Replay mode, they provide the Helios Engine with a deterministic guide for fetching the correct SsaGraph for each frame.

\item \textbf{GasChunk}: A pre-computed value representing the cumulative static gas cost of a sequence of operations. This sequence is defined as the set of instructions occurring between two specific, pre-defined opcodes that interact with the gas counter. This metadata is attached to the SsaGraph and allows the Traced Interpreter to perform a single, bulk gas deduction instead of per-instruction accounting, reducing overhead while maintaining gas-semantic equivalence.

\end{itemize}

\subsection{Component Design and Implementation}
This section details the internal design and mechanisms of each of Helios's four primary components. It describes how each component fulfills its role in the end-to-end transaction lifecycle, transforming its inputs into the data structures required by the next stage of the pipeline.

\subsubsection{Path Tracer: Lightweight Execution Path Tracing}
The Path Tracer is the system's instrumentation component, responsible for observing native EVM execution and producing the raw PathLog data structure alongside TxPlan and GasChunk.

\noindent\textbf{Instrumentation Mechanism.} Path Tracer implements non-invasive instrumentation via the EVM's Hook interface, subscribing to six event types: \texttt{step} and \texttt{step\_end} for opcode-level observation, \texttt{call} and \texttt{call\_end} for external invocations, and \texttt{create} and \texttt{create\_end} for contract deployment. This hook-based design decouples the tracer from the interpreter, enabling passive observation without modifying execution semantics.

To capture stack data dependencies, the tracer employs a shadow stack. This shadow stack mirrors the EVM's value stack but stores 32-bit Log Sequence Numbers (LSNs) instead of 256-bit values. Each LSN uniquely identifies the operation that produced the corresponding value on the EVM stack.

The tracing process, detailed in Algorithm 1, is driven by the step_end hook, which fires after each opcode execution. For a given opcode, the algorithm first determines the number of required inputs and pops the corresponding LSNs from the shadow stack to form the dependency list. Next, a new LSN is assigned to the current operation. If the operation produces a stack output, this new LSN is pushed onto the shadow stack, tracking the provenance of the new value. Crucially, for stack manipulation opcodes like DUP and SWAP that do not create new values but reorder existing ones, the algorithm mirrors these structural changes on the shadow stack to maintain a one-to-one correspondence with the EVM's value stack. This process ensures that the generated PathLog entry correctly links each operation to the LSNs of its true data dependencies.

\noindent\textbf{Metadata Generation.} The Path Tracer is also responsible for generating two key metadata structures: GasChunk and TxPlan. To generate GasChunk metadata, the tracer identifies a set of six gas delimiter opcodes, namely GAS, RETURN, STOP, REVERT, CREATE, and CREATE2. The tracer accumulates the static gas costs of all operations executed between two consecutive delimiters. Upon encountering a delimiter, it finalizes a GasChunk entry containing the accumulated cost. If an execution path terminates without an explicit delimiter, a synthetic STOP is considered to ensure all paths are properly chunked.

The TxPlan for a transaction is constructed using a placeholder mechanism. When a new frame is entered via the call or create hook, a placeholder is appended to the current TxPlan. When the frame execution completes via the call\_end or create\_end hook, the final, computed PathDigest for that frame replaces the placeholder. This ensures the TxPlan accurately reflects the final sequence of executed paths.

\noindent\textbf{Path Validation and Filtering.} To ensure that system resources are spent only on reusable paths, the tracer performs a health check. During the call\_end hook, it inspects the frame's exit status. Paths that terminate due to VM-level exceptional conditions, specifically out-of-gas errors, are discarded. In contrast, deterministic application-level terminations, including both successful returns and REVERT operations, are retained and cached. This distinction is critical because REVERT paths represent reproducible control-flow branches such as failed require checks or insufficient balance validations, which exhibit high reusability across transactions. VM-level exceptions like OOG, however, exhibit low reusability, as an OOG exception may manifest at any opcode depending on the transaction's gas limit. Recording all possible OOG points would induce exponential path explosion. For a sequence of $n$ opcodes, tracking every potential OOG point generates $O(n)$ distinct failure paths, fragmenting the cache without improving hit rates for deterministic execution. Consequently, only deterministically terminated paths, whether successful or reverted, are formatted into PathLog entries and forwarded to the SSA Optimizer.

\subsubsection{SSA Optimizer: Graph Construction and Optimization}
The SSA Optimizer is a pure-function component that transforms a raw PathLog from the Path Tracer into an optimized SsaGraph and an associated constant table. This process involves four distinct stages.

\noindent\textbf{Graph Construction.} The optimizer first constructs an initial SsaGraph from the input PathLog. Each entry in the PathLog's sequence is converted into a corresponding node in the graph. Directed edges are then created to represent data dependencies by connecting each node to the predecessor nodes indicated in its $D_{in}$ LSN list. The result is a direct graph-based representation of the linear trace. 

\noindent\textbf{Three-Stage Optimization Pipeline.} The initial graph then undergoes a three-stage optimization pipeline to eliminate computational redundancy: Constant Folding, Dead Code Elimination, and Common Subexpression Elimination. This specific ordering exploits cascading optimization opportunities whereby constant propagation exposes previously unreachable dead code, and the subsequent elimination of dead operations narrows the search space for common subexpression detection.

\begin{itemize}[leftmargin=0pt, itemindent=0pt, labelwidth=1em, labelsep=0.5em]

\item \textbf{Constant Folding.} The first pass identifies all nodes corresponding to PUSH instructions. Their immediate values are extracted and placed into a constant table. The optimizer then iteratively propagates these constants through subsequent nodes that have no observable side effects, specifically operations that do not modify memory, storage, or system state. Nodes whose computations are fully resolved at compile time are marked as REMOVED, and their outputs are added to the constant table.

\item \textbf{Dead Code Elimination.} The second pass performs a backward dataflow analysis, starting from nodes that have observable side effects. Any node whose output is not consumed by a non-removed successor is also marked as REMOVED. This process repeats until a fixed point is reached, ensuring that all computationally unnecessary operations are pruned from the graph.

\item \textbf{Common Subexpression Elimination.} The final pass identifies and merges redundant computations. To do this, it constructs a unique computational fingerprint for each side-effect-free operation. This fingerprint is a deterministic value derived from the operation's opcode and the LSNs of its input nodes. Formally, an operation with opcode $o$ consuming inputs from nodes with LSNs $\ell_i$ and $\ell_j$ yields the fingerprint $\langle o, i, j \rangle$. For example, an \texttt{ADD} operation with inputs $\ell_5$ and $\ell_{12}$ produces the fingerprint $\langle \texttt{ADD}, 5, 12 \rangle$. Nodes that share an identical fingerprint are considered redundant and are unified, with all consuming nodes redirected to reference the first canonical occurrence.

\end{itemize}

\noindent\textbf{GasChunk Integration.} Following the optimization pipeline, the optimizer integrates the GasChunk metadata collected by the Path Tracer. It retrieves the list of GasChunks from the PathLog and attaches each pre-computed gas cost to its corresponding delimiter node within the SsaGraph. This annotation embeds the gas accounting information directly into the executable graph structure.

\noindent\textbf{Graph Compaction and Output.} In the final stage, the optimizer physically deletes all nodes previously marked as REMOVED to produce a compact graph. It finalizes the constant table, containing all immediate values and folded constants from the optimization phase. The resulting SsaGraph, its constant table, and associated identifiers are then transmitted to the Path Cache for storage.

\subsubsection{Path Cache: Execution Path Memoization}
To efficiently support both the probabilistic lookups of Online mode and the deterministic lookups of Replay mode, the Path Cache employs a two-tier architecture that separates prediction logic from canonical storage.

\begin{itemize}[leftmargin=0pt, itemindent=0pt, labelwidth=1em, labelsep=0.5em]

\item \textbf{Path Mapping Layer (PML)}: A frequency-based prediction index that supports Online mode's speculative execution. For each CallSig, it maintains a dual-index structure consisting of a frequency map for O(1) frequency queries and a sorted index for O(log k) maximum frequency retrieval, where k denotes the number of distinct frequency values. The PML returns the unique PathDigest with maximum access count for a given CallSig. If multiple paths share the maximum frequency, the lookup returns no prediction, prioritizing prediction accuracy over coverage as low-confidence speculation would incur guard validation overhead.

\item \textbf{Graph Mapping Layer (GML)}: A deterministic key-value store that serves as the canonical repository for all optimized execution artifacts. It implements the code/data separation strategy through two distinct mappings. The first maps each PathDigest to its corresponding SsaGraph structure, enabling code reuse across contracts with identical bytecode structure. The second maps each DataKey to a contract-specific constant table, ensuring correct constant retrieval for contracts that share code but differ in embedded immediate values.

\end{itemize}

\noindent\textbf{Query Protocols.} The cache's query protocol differs based on the operational mode. In Online mode, a query begins at the PML. The engine provides a CallSig, and the PML retrieves the sorted index for that CallSig under a read lock. It inspects the highest frequency set and returns the associated PathDigest only if it is unique; if multiple paths share the maximum frequency, the query returns no prediction. When a prediction succeeds, the PathDigest is combined with the contract's code hash to form a DataKey, which is then used to query the GML for the SsaGraph and its corresponding constant table. The PathDigest is also returned to the engine for use in the subsequent feedback loop. The complete lookup process is detailed in Algorithm~\ref{alg:online-lookup}.

In contrast, Replay mode bypasses the PML entirely. The engine provides a PathDigest retrieved from a TxPlan and a DataKey. These keys are used to perform a direct, deterministic lookup in the GML to retrieve the SsaGraph and its constant table. For any path referenced in a TxPlan, this lookup is guaranteed to succeed.

\noindent\textbf{Update and Persistence.} The cache's update protocol distinguishes between two types of events, each serving a different purpose in maintaining the cache's accuracy and coverage. The first type occurs when the SSA Optimizer generates a new SsaGraph, triggering a comprehensive update. The new graph and its constant table are stored in the GML, while the PML initializes or updates the frequency statistics for the corresponding CallSig-PathDigest pair. This mechanism serves as the primary method for populating the cache with new content discovered during native execution.

The second type of update is triggered when the Helios Engine successfully completes a transaction using a cached SsaGraph in Online mode. This event initiates a lightweight feedback update in which the engine signals the PML to increment the access counter for the specific PathDigest that was executed. The PML acquires a write lock on the corresponding frequency statistics and performs an atomic update in O(log k) time: it removes the PathDigest from its old frequency set in the sorted index, increments its frequency in the frequency map, and inserts it into the new frequency set. This feedback loop reinforces the dominance of successful and frequently executed paths, directly improving the accuracy of future predictions. The complete update protocol is formalized in Algorithm~\ref{alg:path-frequency-update}.

Because the Path Tracer and SSA Optimizer execute asynchronously relative to the Helios Engine, PML operations are protected by fine-grained read-write locks on a per-CallSig basis to ensure thread safety while maximizing concurrency. Read operations, such as hot path prediction, allow concurrent access, while write operations, such as frequency updates, acquire exclusive locks for bounded time.

\noindent\textbf{Checkpoint generation and cleanup.} To ensure durability and enable fast node restarts, the system generates checkpoints every N blocks, serializing the cache's contents to disk. The default policy preserves all cached paths, but a pruning mechanism based on CallSig access frequency is provided. The access threshold can be configured to evict CallSigs, along with their associated graphs and data, falling below the specified frequency, trading coverage for storage efficiency.

\noindent\textbf{Recovery and bootstrapping.} Upon node restart, the Path Cache loads verified high-value paths from checkpoints, immediately achieving high prediction accuracy without a cold-start learning phase. The sorted indices are reconstructed in O(N log k) time during deserialization, where N is the total number of unique paths. The loaded paths represent optimized hotspots from historical execution, validated through frequency and predictability metrics. For paths absent from checkpoints, the system employs lazy regeneration, tracing and optimizing them on-demand during execution to gradually expand path coverage.

\subsubsection{Helios Engine: Dual-Mode Execution Orchestrator}
The Helios Engine is the central orchestrator that coordinates transaction processing. It integrates with the host EVM implementation by replacing its per-frame execution loop while inheriting its mature state and memory management infrastructure. For instance, in its integration with Revm, Helios leverages the host's high-performance memory subsystem, which amortizes allocation overhead by partitioning a pre-allocated byte array across multiple frames via logical checkpointing. Similarly, it inherits Revm's optimized storage access model, which uses in-memory caching and prewarming to avoid redundant disk lookups and a transaction-local journal to buffer state changes for atomic commits. By building upon this robust foundation for state handling, the Helios Engine can focus its design exclusively on optimizing the computational flow within each execution frame. It assumes full control over how opcodes are interpreted, selecting between its two internal interpreters---the Traced Interpreter and the Native Interpreter---based on the operational mode and cache state.

\noindent\textbf{Transaction-Scoped Execution Model.} A core design principle of the engine is its transaction-scoped execution model. All execution attempts, whether using the Traced Interpreter or the Native Interpreter, operate at the granularity of a full transaction. If any failure occurs during a traced execution---such as a cache miss, a guard violation, or an out-of-gas condition---the engine discards all partial work for that transaction and restarts its execution from the beginning using the Native Interpreter. This strategy eliminates the need for complex, fine-grained state checkpointing or rollback mechanisms, leveraging the EVM's inherent transaction-level atomicity to ensure correctness.

\noindent\textbf{The Traced Interpreter.} When the Path Cache returns a valid SsaGraph, the engine dispatches execution to the Traced Interpreter. Its execution loop, formally detailed in Algorithm X, is designed for high-speed graph processing and differs from a standard EVM interpreter in three key aspects.

First, it replaces the EVM's stack machine with a register-based model. As shown in the algorithm, a virtual register file is allocated, and each SsaGraph node's result is stored at an index corresponding to its LSN. An operation's inputs are sourced directly from this array, eliminating all stack manipulation overhead.

Second, in Online mode, it enforces speculative execution guards. The algorithm demonstrates how, before executing a JUMP or JUMPI, the interpreter computes the runtime jump target and validates it against the statically cached target from the SsaGraph. Any mismatch triggers an immediate transaction-level fallback. These guards are disabled in Replay mode.

Third, it implements chunked gas accounting, distinguishing between static and dynamic gas costs. For most instructions, no check is performed. At delimiter nodes, the cumulative static cost from the GasChunk is deducted in a single operation. Any instruction with dynamic gas costs such as memory expansion triggers a separate, per-instruction calculation and deduction. This hybrid approach maintains exact gas-semantic equivalence while minimizing verification overhead.

\subsection{Security Considerations}

Beyond the JIT Bomb resistance established through the path-driven paradigm in \S\ref{sec:path-vs-contract}, Helios's design inherently mitigates path explosion attacks. An adversary might attempt to degrade system performance by constructing malicious contracts that generate millions of unique execution paths for a single function signature, potentially flooding the cache and consuming optimization resources.

Helios's architecture naturally defends against this attack vector through three complementary mechanisms. The frequency-based Path Mapping Layer ensures that only paths with demonstrated reusability are predicted and accelerated. Attack-generated paths remain perpetually classified as cold paths due to low execution counts, excluded from the prediction model. The checkpoint pruning mechanism evicts CallSigs with access frequencies below a configurable threshold, preventing malicious cold paths from consuming long-term storage while retaining legitimate hot paths. The transaction-scoped execution model ensures that cache misses simply trigger fallback to the Native Interpreter, maintaining correctness and baseline performance for unpredicted paths.

Consequently, path explosion attacks impose only bounded costs on asynchronous tracing and temporary cache occupancy without degrading performance for legitimate transactions. This robustness emerges naturally from the frequency-based filtering and bounded resource allocation inherent to Helios's design.

\section{Evaluation}
This section evaluates Helios under both controlled microbenchmarks and real-world mainnet workloads to assess its effectiveness as a path-driven execution engine for EVM optimization. The evaluation aims to answer three core research questions:

\noindent\textbf{RQ1: Optimization Overhead.} We compare Helios's lightweight path tracing against full contract tracing in terms of time and space cost, assessing whether the overhead remains acceptable for online deployment in production blockchain nodes.

\noindent\textbf{RQ2: Performance Gains.} We evaluate the speedup achieved by Helios relative to native EVM execution and existing optimization approaches, examining whether the path-driven optimization strategy delivers consistent improvements across diverse smart contract workloads.

\noindent\textbf{RQ3: System Applicability.} We assess the performance of Replay mode and Online mode in their respective target scenarios---archive node acceleration and full node optimization.

The evaluation proceeds in three stages. \S\ref{sec:experiment-setup} describes the experimental setup, including hardware configuration, baseline systems, and workload selection. \S\ref{sec:micro-benchmark} presents microbenchmark results for three representative DeFi transactions, isolating the impact of path tracing overhead, execution speedup, and SSA optimization effectiveness. \S\ref{sec:mainet} analyzes Helios's performance on mainnet blocks, validating path locality assumptions and measuring aggregate throughput improvements.

\subsection{Experimental Setup}
\label{sec:experiment-setup}
All experiments were conducted on an AWS r7i.2xlarge instance with 8 vCPUs and 64 GB of memory. Helios is implemented in Rust and compiled with release optimizations enabled. We evaluate against four baseline systems. Geth v1.9.9 serves as the reference Go-based Ethereum client for native EVM execution. Revm v22.0.1 provides a highly optimized Rust-based EVM implementation with substantially faster native performance. Forerunner is tested in two variants: the original Geth-based implementation and a mocked Revm version that replicates its tracing and optimization strategy. Revmc v0.1.0 represents a JIT compilation approach to EVM optimization, evaluated in both native and optimized execution modes. Revmc bundles its own Revm execution environment, which may differ from our standalone Revm v22.0.1 baseline.

\subsection{Microbenchmark Performance}
\label{sec:micro-benchmark}
We evaluate Helios using three representative DeFi transactions of increasing complexity. \textbf{ERC20-Transfer} executes 492 opcodes for token transfers, representing the most frequent transaction type on Ethereum. \textbf{Uniswap-V2-Swap-1hop} performs single-pool exchanges with 5,667 opcodes, typical of high-liquidity pairs. \textbf{Uniswap-V2-Swap-4hop} executes multi-pool routing across 18,063 opcodes, representing complex swap paths for long-tail assets. These benchmarks enable systematic analysis of optimization overhead, execution speedup relative to baselines, and the relationship between opcode reduction and performance gains. Each transaction executes 100 times with warm caches, reporting median values.

\subsubsection{Optimization Overhead}

This subsection addresses \textbf{RQ1} by quantifying the optimization overhead in terms of tracing time and artifact storage footprint. Table~\ref{tab:optimization_overhead} compares Helios against Forerunner's full-tracing approach on both Geth and Revm. We note that our Forerunner-Revm implementation employs intrusive instrumentation for tracing, while Helios uses a hook-based mechanism that preserves native execution performance.

Helios achieves lower tracing overhead than full-tracing approaches. For ERC20-Transfer, Helios completes path tracing in 23.2~μs, a 12.5× speedup over Forerunner-Geth. The tracing latency remains comparable to the optimized Forerunner-Revm implementation. As contract complexity increases, the advantage over Forerunner-Geth diminishes to 2.4× for Uniswap-Swap-1hop and 1.4× for Uniswap-Swap-4hop. For complex contracts, the volume of executed instructions dominates tracing cost regardless of strategy.

Storage efficiency gains are more pronounced. Helios achieves 82.7× compression over Forerunner-Geth for ERC20-Transfer, 13.0× for Uniswap-Swap-1hop, and 16.2× for Uniswap-Swap-4hop. Relative to Forerunner-Revm, Helios achieves 9.4× compression for ERC20-Transfer, 9.2× for Uniswap-Swap-1hop, and 16.4× for Uniswap-Swap-4hop. The absolute artifact sizes of 4.8~KB, 70.2~KB, and 122.9~KB enable efficient in-memory caching without memory pressure. For the most complex benchmark, Helios stores the optimized path in 122.9~KB compared to Forerunner-Revm's 2,017.5~KB, a 16.4× reduction that allows hundreds of cached paths to fit within typical L3 cache budgets. This sub-megabyte footprint per contract makes Helios practical for online deployment where storage overhead directly impacts scalability.

With tracing latency in the sub-millisecond range and storage requirements measured in kilobytes, we now evaluate the execution performance gains.

\subsubsection{Execution Performance}

This subsection addresses \textbf{RQ2} by evaluating execution speedup on optimized paths. Figure~\ref{fig:microbench_speedup} presents acceleration factors for Revm-based systems normalized against Revm Native, which represents state-of-the-art substrate efficiency. Table~\ref{tab:substrate_comparison} compares Geth-based and Revm-based implementations.

Helios achieves speedups of 1.14×, 2.00×, and 1.77× for ERC20-Transfer, Uniswap-Swap-1hop, and Uniswap-Swap-4hop. Performance peaks at medium-complexity Uniswap-1hop, where repetitive automated market maker computations create optimization opportunities. Helios reduces execution time from 62.0~μs to 31.0~μs by eliminating redundant arithmetic and logic operations through SSA-based path specialization. The modest gain on simple ERC20-Transfer suggests highly optimized baselines leave limited room for interpreter-level optimization.

\noindent\textbf{Substrate Efficiency Constraint.}
Substrate selection fundamentally constrains optimization effectiveness. While Forerunner-Geth reduces Geth Native execution time by 2.5× to 5.8× across benchmarks, optimized Geth execution at 35.75~μs for ERC20-Transfer remains 7.2× slower than unoptimized Revm at 4.94~μs. This disparity diminishes on complex workloads, with Forerunner-Geth achieving near-parity on Uniswap-4hop at 167.38~μs versus 172.49~μs. Even advanced optimization cannot overcome substrate efficiency gaps on simple workloads. We therefore focus on Revm-based systems to isolate optimization technique effectiveness.

\noindent\textbf{Lightweight vs. Full-Context Tracing.}
Comparing Revm-based systems isolates tracing strategy impact from implementation artifacts. Both Helios and Forerunner-Revm capture optimization opportunities from executed traces at path-level granularity. The key distinction is tracing scope: Helios employs lightweight stack-only tracing, whereas Forerunner performs full-context tracing capturing stack frames, memory snapshots, and contract state. Helios outperforms Forerunner-Revm by 1.04×, 1.27×, and 1.34× across benchmarks. On Uniswap-1hop, Helios achieves 2.00× versus Forerunner-Revm's 1.58×, reducing execution time from 39.20~μs to 30.96~μs.

This advantage stems from compact optimization artifacts. Lightweight tracing generates 4.87~KB versus 402.8~KB for full-context tracing (Table~\ref{tab:optimization_overhead}). Reduced artifact size enables faster loading and deserialization when replaying optimized paths, while simpler trace structure reduces interpreter overhead by processing fewer metadata fields per instruction. This decreases cache pressure and per-instruction cost. The lightweight approach sacrifices no optimization effectiveness for deterministic execution paths, which constitute the majority of mainnet transactions.

\noindent\textbf{JIT Compilation Tradeoffs.}
Revmc's just-in-time compilation demonstrates mixed effectiveness. For ERC20-Transfer, Revmc underperforms the native baseline by 11\% despite using pre-compiled machine code. Several factors likely contribute. Modern interpreters like Revm employ micro-optimizations such as computed gotos, inline caching, and specialized fast paths. These optimizations benefit from whole-program compilation. JIT-generated code, constrained by runtime generation, may fail to achieve comparable efficiency. This limitation becomes particularly significant for short execution sequences where instruction cache effects and setup overhead dominate.

Performance improves on complex workloads to 1.46× and 1.36× for Uniswap-1hop and Uniswap-4hop, suggesting longer execution sequences better amortize fixed overheads. However, Revmc remains inferior to Helios at 2.00× and 1.77× on these benchmarks, with geometric mean speedup of 1.24× versus 1.64×.

These results suggest interpreter-level optimization offers advantages over JIT compilation for EVM workloads. Helios performs SSA transformations on abstract opcode sequences and replays optimized paths through Helios Engine, preserving micro-architectural optimizations in the hand-tuned interpreter while reducing instruction count. JIT compilation replaces the interpreter entirely, requiring runtime code generation to match pre-compiled interpreter efficiency. This appears challenging for microsecond-scale EVM transactions. However, definitive conclusions would require controlled experiments isolating individual optimization components.

To understand the mechanisms underlying these performance gains, we now decompose the impact of individual SSA optimization passes and examine why significant opcode reduction translates to moderate execution speedup.

\subsubsection{Opcode Reduction and Speedup Discrepancy}

This subsection provides deeper insight into \textbf{RQ2} by examining the relationship between opcode reduction and execution speedup across the three benchmarks.

\noindent\textbf{Optimization Effectiveness.} Constant folding dominates opcode reduction, accounting for 97.5\%, 97.8\%, and 97.9\% of eliminated instructions as is shown in Table~\ref{tab:opcode_reduction}. SSA-based dataflow analysis propagates compile-time constants through execution paths, enabling elimination of computations with known results, unreachable branches, and redundant operations. Common subexpression elimination and dead code elimination contribute 2.1-2.5\% combined, indicating limited redundancy after constant propagation. Consistent reduction rates of 76.6-82.3\% across varying workload complexities suggest SSA optimization effectiveness is largely invariant to contract scale.

\noindent\textbf{Understanding the Speedup Discrepancy.} Helios reduces opcode count by 76-82\% through SSA-based optimization, yet achieves only 1.14-2.00× speedup rather than the 4.28-5.66× theoretical prediction based on instruction count proportionality. This discrepancy arises from deliberate design constraints that prioritize economic compatibility over maximal performance gains.

Our optimization strategy targets lightweight operations such as stack manipulation, arithmetic, and control flow. These operations execute in nanoseconds individually but account for the majority of eliminated instructions. Constant folding removes these operations systematically, yielding cumulative microsecond-scale savings per transaction that aggregate to millisecond-scale reductions in block processing time across hundreds of transactions per block. Computationally intensive operations such as KECCAK256 and storage accesses remain unoptimized. As established in \S\ref{sec:motivation}, these operations involve dynamic gas metering. We leave these operations unoptimized to avoid gas metering complications.

The SSA graph execution model incurs additional overhead. Each optimized path traversal requires metadata access, register lookups, and dispatch logic. When eliminated opcodes execute in nanoseconds, these graph traversal costs become proportionally significant relative to the savings achieved. The SSA representation trades interpretation overhead for portability and analyzability without requiring JIT compilation infrastructure. The observed 1.14-2.00× speedups demonstrate that substantial opcode reduction yields measurable performance gains within these architectural constraints. \s\ref{sec:discussion} explores further optimization opportunities under the current design framework.

\subsection{Mainnet Workload Analysis}
\label{sec:mainet}

Having validated Helios's optimization effectiveness on isolated transactions (\S\ref{sec:micro-benchmark}), we now evaluate performance and storage overhead on real-world workloads using 1,000 consecutive mainnet blocks numbered 19,476,587 through 19,477,586. These blocks contain 876,883 total transactions, of which 567,372 are smart contract invocations. We exclude 309,511 pure transfers because they involve no contract execution and fall outside Helios's optimization scope.

We define \textit{execution coverage} as the fraction of contract executions whose PathDigest and DataKey pair matches a cached optimization artifact. Coverage quantifies cache effectiveness by measuring how many executions reuse pre-computed optimizations without re-tracing. This section quantifies storage requirements, validates speedup under production workloads, and analyzes deployment tradeoffs between Replay and Online modes.

\subsubsection{Storage Overhead}

This subsection continues addressing \textbf{RQ1} by analyzing storage requirements to assess Helios's practicality for production deployment. We generate optimization artifacts for 5,000 consecutive blocks (#19,476,587–#19,481,586) to ensure cache warmup and path convergence, then evaluate storage-coverage tradeoffs under different caching strategies.

\noindent\textbf{Baseline Storage Requirements.}
Figure~\ref{fig:storage_growth} shows storage growth for block data and Helios optimization artifacts across 1,000 to 5,000 blocks. Processing 5,000 blocks generates 426~MB of optimization artifacts when caching all unique execution paths without filtering, representing 41.9\% overhead relative to raw block data. Storage overhead exhibits sub-linear growth. The first 1,000 blocks incur 52.2\% overhead, decreasing to 41.9\% at 5,000 blocks due to path convergence.

\noindent\textbf{Frequency-Based Filtering.}
Path locality established in \S\ref{sec:frame-level-caching} demonstrates that execution frequency follows a Pareto distribution. We exploit this property through frequency-based filtering, retaining only paths executed at least $f$ times across the 5,000-block warmup period. This approach offers implementation simplicity compared to percentile-based thresholds while naturally adapting to workload characteristics. Table~\ref{tab:storage_coverage_tradeoff} quantifies the storage-coverage tradeoff across different frequency thresholds.

Applying frequency $\geq$10 filtering reduces storage to 50~MB while maintaining 96.5\% execution coverage and 58.0\% Top-1 hit rate. More aggressive thresholds yield diminishing returns. Frequency $\geq$100 achieves only 1.9\% overhead but sacrifices 11\% execution coverage. Frequency $\geq$500 becomes impractical at 69.9\% coverage despite minimal 0.3\% storage cost. The frequency $\geq$10 threshold balances storage efficiency and coverage preservation, motivating its selection for Online mode deployment. We investigate the performance implications of this filtering strategy below.

\subsubsection{Replay Mode Performance}

This subsection addresses \textbf{RQ2} and \textbf{RQ3} by evaluating Replay mode on 1,000 blocks to establish performance upper bounds under perfect path knowledge for archive node scenarios. This represents the oracle baseline where all execution paths are known deterministically.

Figure~\ref{fig:replay_speedup_dist} presents the speedup distribution. Helios achieves a median speedup of 6.60×. The distribution exhibits strong tail performance with the 75th percentile at 13.88× and the 90th percentile at 21.43×. Only 5.4\% of blocks experience slowdown relative to baseline execution. The distribution concentrates in the 5-10× range at 22.6\% and 10-20× range at 25.6\%, demonstrating consistent acceleration across diverse workloads.

Replay mode proves particularly valuable for archive nodes performing historical synchronization, where blockchain history is optimized once and replayed efficiently for subsequent queries or re-synchronizations.

\subsubsection{Online Mode Effectiveness}

This subsection addresses \textbf{RQ2} and \textbf{RQ3} by evaluating Online mode for live transaction execution where execution paths are unknown a priori. We evaluate performance on 1,000 blocks immediately following the 5,000-block warmup period, ensuring the test set contains fresh transactions not seen during cache construction. We evaluate performance under two configurations. Online mode without filtering caches all paths from the warmup period. Online mode with frequency $\geq$10 filtering retains only paths exceeding the frequency threshold, as motivated by Table~\ref{tab:storage_coverage_tradeoff}.

\noindent\textbf{Online Mode Without Filtering.}
Figure~\ref{fig:online_no_filter} presents the speedup distribution when caching all paths. Online mode achieves a median speedup of 4.56×, underperforming Replay mode's 6.60× by 31\%. The distribution concentrates in the 5-10× range at 34.0\%, with the 75th percentile at 7.12× and the 90th percentile at 9.85×. Only 8.8\% of blocks exhibit slowdown relative to baseline execution.

\noindent\textbf{Online Mode With Frequency Filtering.}
Figure~\ref{fig:online_filtered} presents the speedup distribution under frequency $\geq$10 filtering. Median speedup drops to 2.05×, representing a 55\% reduction relative to unfiltered Online mode. The distribution shifts toward lower speedup ranges, with 36.2\% of blocks concentrated in the 1-2× range. However, tail performance remains competitive at the 90th percentile with 9.01× speedup. Performance degradation primarily affects median and lower percentiles rather than tail workloads.

\noindent\textbf{Performance Degradation Analysis.}
Three factors contribute to Online mode's performance degradation relative to Replay mode. First, greedy Top-1 path selection achieves only 58.0\% hit rate under frequency $\geq$10 filtering, causing 42\% of transactions to fall back to native execution. Contracts with multiple high-frequency paths driven by input-dependent control flow cannot be fully covered by single-path caching. Second, Helios employs transaction-level rollback for path mispredictions. When a path divergence occurs during execution, the entire transaction rolls back to native execution rather than switching to an alternative path mid-execution. This all-or-nothing strategy amplifies the penalty for cache misses, as partially completed optimized execution provides no benefit. Third, per-transaction overhead from path prediction and cache lookup becomes proportionally significant when optimized paths execute in microseconds. These limitations suggest opportunities for multi-path caching, incremental rollback mechanisms, and adaptive path selection strategies, which we discuss in \S\ref{sec:discussion}.

\section{Evaluation}
This section evaluates Helios under both controlled microbenchmarks and real-world mainnet workloads to assess its effectiveness as a path-driven execution engine for EVM optimization. The evaluation aims to answer three core research questions:

\noindent\textbf{RQ1: Optimization Overhead.} We compare Helios's lightweight path tracing against full contract tracing in terms of time and space cost, assessing whether the overhead remains acceptable for online deployment in production blockchain nodes.

\noindent\textbf{RQ2: Performance Gains.} We evaluate the speedup achieved by Helios relative to native EVM execution and existing optimization approaches, examining whether the path-driven optimization strategy delivers consistent improvements across diverse smart contract workloads.

\noindent\textbf{RQ3: System Applicability.} We assess the performance of Replay mode and Online mode in their respective target scenarios---archive node acceleration and full node optimization.

The evaluation proceeds in three stages. \S\ref{sec:experiment-setup} describes the experimental setup, including hardware configuration, baseline systems, and workload selection. \S\ref{sec:micro-benchmark} presents microbenchmark results for three representative DeFi transactions, isolating the impact of path tracing overhead, execution speedup, and SSA optimization effectiveness. \S\ref{sec:mainet} analyzes Helios's performance on mainnet blocks, validating path locality assumptions and measuring aggregate throughput improvements.

\subsection{Experimental Setup}
\label{sec:experiment-setup}
All experiments were conducted on an AWS r7i.2xlarge instance with 8 vCPUs and 64 GB of memory. Helios is implemented in Rust and compiled with release optimizations enabled. We evaluate against four baseline systems. Geth v1.9.9 serves as the reference Go-based Ethereum client for native EVM execution. Revm v22.0.1 provides a highly optimized Rust-based EVM implementation with substantially faster native performance. Forerunner is tested in two variants: the original Geth-based implementation and a mocked Revm version that replicates its tracing and optimization strategy. Revmc v0.1.0 represents a JIT compilation approach to EVM optimization, evaluated in both native and optimized execution modes. Revmc bundles its own Revm execution environment, which may differ from our standalone Revm v22.0.1 baseline.

\subsection{Microbenchmark Performance}
\label{sec:micro-benchmark}
We evaluate Helios using three representative DeFi transactions of increasing complexity. \textbf{ERC20-Transfer} executes 492 opcodes for token transfers, representing the most frequent transaction type on Ethereum. \textbf{Uniswap-V2-Swap-1hop} performs single-pool exchanges with 5,667 opcodes, typical of high-liquidity pairs. \textbf{Uniswap-V2-Swap-4hop} executes multi-pool routing across 18,063 opcodes, representing complex swap paths for long-tail assets. These benchmarks enable systematic analysis of optimization overhead, execution speedup relative to baselines, and the relationship between opcode reduction and performance gains. Each transaction executes 100 times with warm caches, reporting median values.

\subsubsection{Optimization Overhead}

This subsection addresses \textbf{RQ1} by quantifying the optimization overhead in terms of tracing time and artifact storage footprint. Table~\ref{tab:optimization_overhead} compares Helios against Forerunner's full-tracing approach on both Geth and Revm. We note that our Forerunner-Revm implementation employs intrusive instrumentation for tracing, while Helios uses a hook-based mechanism that preserves native execution performance.

Helios achieves lower tracing overhead than full-tracing approaches. For ERC20-Transfer, Helios completes path tracing in 23.2~μs, a 12.5× speedup over Forerunner-Geth. The tracing latency remains comparable to the optimized Forerunner-Revm implementation. As contract complexity increases, the advantage over Forerunner-Geth diminishes to 2.4× for Uniswap-Swap-1hop and 1.4× for Uniswap-Swap-4hop. For complex contracts, the volume of executed instructions dominates tracing cost regardless of strategy.

Storage efficiency gains are more pronounced. Helios achieves 82.7× compression over Forerunner-Geth for ERC20-Transfer, 13.0× for Uniswap-Swap-1hop, and 16.2× for Uniswap-Swap-4hop. Relative to Forerunner-Revm, Helios achieves 9.4× compression for ERC20-Transfer, 9.2× for Uniswap-Swap-1hop, and 16.4× for Uniswap-Swap-4hop. The absolute artifact sizes of 4.8~KB, 70.2~KB, and 122.9~KB enable efficient in-memory caching without memory pressure. For the most complex benchmark, Helios stores the optimized path in 122.9~KB compared to Forerunner-Revm's 2,017.5~KB, a 16.4× reduction that allows hundreds of cached paths to fit within typical L3 cache budgets. This sub-megabyte footprint per contract makes Helios practical for online deployment where storage overhead directly impacts scalability.

With tracing latency in the sub-millisecond range and storage requirements measured in kilobytes, we now evaluate the execution performance gains.

\subsubsection{Execution Performance}

This subsection addresses \textbf{RQ2} by evaluating execution speedup on optimized paths. Figure~\ref{fig:microbench_speedup} presents acceleration factors for Revm-based systems normalized against Revm Native, which represents state-of-the-art substrate efficiency. Table~\ref{tab:substrate_comparison} compares Geth-based and Revm-based implementations.

Helios achieves speedups of 1.14×, 2.00×, and 1.77× for ERC20-Transfer, Uniswap-Swap-1hop, and Uniswap-Swap-4hop. Performance peaks at medium-complexity Uniswap-1hop, where repetitive automated market maker computations create optimization opportunities. Helios reduces execution time from 62.0~μs to 31.0~μs by eliminating redundant arithmetic and logic operations through SSA-based path specialization. The modest gain on simple ERC20-Transfer suggests highly optimized baselines leave limited room for interpreter-level optimization.

\noindent\textbf{Substrate Efficiency Constraint.}
Substrate selection fundamentally constrains optimization effectiveness. While Forerunner-Geth reduces Geth Native execution time by 2.5× to 5.8× across benchmarks, optimized Geth execution at 35.75~μs for ERC20-Transfer remains 7.2× slower than unoptimized Revm at 4.94~μs. This disparity diminishes on complex workloads, with Forerunner-Geth achieving near-parity on Uniswap-4hop at 167.38~μs versus 172.49~μs. Even advanced optimization cannot overcome substrate efficiency gaps on simple workloads. We therefore focus on Revm-based systems to isolate optimization technique effectiveness.

\noindent\textbf{Lightweight vs. Full-Context Tracing.}
Comparing Revm-based systems isolates tracing strategy impact from implementation artifacts. Both Helios and Forerunner-Revm capture optimization opportunities from executed traces at path-level granularity. The key distinction is tracing scope: Helios employs lightweight stack-only tracing, whereas Forerunner performs full-context tracing capturing stack frames, memory snapshots, and contract state. Helios outperforms Forerunner-Revm by 1.04×, 1.27×, and 1.34× across benchmarks. On Uniswap-1hop, Helios achieves 2.00× versus Forerunner-Revm's 1.58×, reducing execution time from 39.20~μs to 30.96~μs.

This advantage stems from compact optimization artifacts. Lightweight tracing generates 4.87~KB versus 402.8~KB for full-context tracing (Table~\ref{tab:optimization_overhead}). Reduced artifact size enables faster loading and deserialization when replaying optimized paths, while simpler trace structure reduces interpreter overhead by processing fewer metadata fields per instruction. This decreases cache pressure and per-instruction cost. The lightweight approach sacrifices no optimization effectiveness for deterministic execution paths, which constitute the majority of mainnet transactions.

\noindent\textbf{JIT Compilation Tradeoffs.}
Revmc's just-in-time compilation demonstrates mixed effectiveness. For ERC20-Transfer, Revmc underperforms the native baseline by 11\% despite using pre-compiled machine code. Several factors likely contribute. Modern interpreters like Revm employ micro-optimizations such as computed gotos, inline caching, and specialized fast paths. These optimizations benefit from whole-program compilation. JIT-generated code, constrained by runtime generation, may fail to achieve comparable efficiency. This limitation becomes particularly significant for short execution sequences where instruction cache effects and setup overhead dominate.

Performance improves on complex workloads to 1.46× and 1.36× for Uniswap-1hop and Uniswap-4hop, suggesting longer execution sequences better amortize fixed overheads. However, Revmc remains inferior to Helios at 2.00× and 1.77× on these benchmarks, with geometric mean speedup of 1.24× versus 1.64×.

These results suggest interpreter-level optimization offers advantages over JIT compilation for EVM workloads. Helios performs SSA transformations on abstract opcode sequences and replays optimized paths through Helios Engine, preserving micro-architectural optimizations in the hand-tuned interpreter while reducing instruction count. JIT compilation replaces the interpreter entirely, requiring runtime code generation to match pre-compiled interpreter efficiency. This appears challenging for microsecond-scale EVM transactions. However, definitive conclusions would require controlled experiments isolating individual optimization components.

To understand the mechanisms underlying these performance gains, we now decompose the impact of individual SSA optimization passes and examine why significant opcode reduction translates to moderate execution speedup.

\subsubsection{Opcode Reduction and Speedup Discrepancy}

This subsection provides deeper insight into \textbf{RQ2} by examining the relationship between opcode reduction and execution speedup across the three benchmarks.

\noindent\textbf{Optimization Effectiveness.} Constant folding dominates opcode reduction, accounting for 97.5\%, 97.8\%, and 97.9\% of eliminated instructions as is shown in Table~\ref{tab:opcode_reduction}. SSA-based dataflow analysis propagates compile-time constants through execution paths, enabling elimination of computations with known results, unreachable branches, and redundant operations. Common subexpression elimination and dead code elimination contribute 2.1-2.5\% combined, indicating limited redundancy after constant propagation. Consistent reduction rates of 76.6-82.3\% across varying workload complexities suggest SSA optimization effectiveness is largely invariant to contract scale.

\noindent\textbf{Understanding the Speedup Discrepancy.} Helios reduces opcode count by 76-82\% through SSA-based optimization, yet achieves only 1.14-2.00× speedup rather than the 4.28-5.66× theoretical prediction based on instruction count proportionality. This discrepancy arises from deliberate design constraints that prioritize economic compatibility over maximal performance gains.

Our optimization strategy targets lightweight operations such as stack manipulation, arithmetic, and control flow. These operations execute in nanoseconds individually but account for the majority of eliminated instructions. Constant folding removes these operations systematically, yielding cumulative microsecond-scale savings per transaction that aggregate to millisecond-scale reductions in block processing time across hundreds of transactions per block. Computationally intensive operations such as KECCAK256 and storage accesses remain unoptimized. As established in \S\ref{sec:motivation}, these operations involve dynamic gas metering. We leave these operations unoptimized to avoid gas metering complications.

The SSA graph execution model incurs additional overhead. Each optimized path traversal requires metadata access, register lookups, and dispatch logic. When eliminated opcodes execute in nanoseconds, these graph traversal costs become proportionally significant relative to the savings achieved. The SSA representation trades interpretation overhead for portability and analyzability without requiring JIT compilation infrastructure. The observed 1.14-2.00× speedups demonstrate that substantial opcode reduction yields measurable performance gains within these architectural constraints. \s\ref{sec:discussion} explores further optimization opportunities under the current design framework.

\subsection{Mainnet Workload Analysis}
\label{sec:mainet}

Having validated Helios's optimization effectiveness on isolated transactions (\S\ref{sec:micro-benchmark}), we now evaluate performance and storage overhead on real-world workloads using 1,000 consecutive mainnet blocks numbered 19,476,587 through 19,477,586. These blocks contain 876,883 total transactions, of which 567,372 are smart contract invocations. We exclude 309,511 pure transfers because they involve no contract execution and fall outside Helios's optimization scope.

We define \textit{execution coverage} as the fraction of contract executions whose PathDigest and DataKey pair matches a cached optimization artifact. Coverage quantifies cache effectiveness by measuring how many executions reuse pre-computed optimizations without re-tracing. This section quantifies storage requirements, validates speedup under production workloads, and analyzes deployment tradeoffs between Replay and Online modes.

\subsubsection{Storage Overhead}

This subsection continues addressing \textbf{RQ1} by analyzing storage requirements to assess Helios's practicality for production deployment. We generate optimization artifacts for 5,000 consecutive blocks (#19,476,587–#19,481,586) to ensure cache warmup and path convergence, then evaluate storage-coverage tradeoffs under different caching strategies.

\noindent\textbf{Baseline Storage Requirements.}
Figure~\ref{fig:storage_growth} shows storage growth for block data and Helios optimization artifacts across 1,000 to 5,000 blocks. Processing 5,000 blocks generates 426~MB of optimization artifacts when caching all unique execution paths without filtering, representing 41.9\% overhead relative to raw block data. Storage overhead exhibits sub-linear growth. The first 1,000 blocks incur 52.2\% overhead, decreasing to 41.9\% at 5,000 blocks due to path convergence.

\noindent\textbf{Frequency-Based Filtering.}
Path locality established in \S\ref{sec:frame-level-caching} demonstrates that execution frequency follows a Pareto distribution. We exploit this property through frequency-based filtering, retaining only paths executed at least $f$ times across the 5,000-block warmup period. This approach offers implementation simplicity compared to percentile-based thresholds while naturally adapting to workload characteristics. Table~\ref{tab:storage_coverage_tradeoff} quantifies the storage-coverage tradeoff across different frequency thresholds.

Applying frequency $\geq$10 filtering reduces storage to 50~MB while maintaining 96.5\% execution coverage and 58.0\% Top-1 hit rate. More aggressive thresholds yield diminishing returns. Frequency $\geq$100 achieves only 1.9\% overhead but sacrifices 11\% execution coverage. Frequency $\geq$500 becomes impractical at 69.9\% coverage despite minimal 0.3\% storage cost. The frequency $\geq$10 threshold balances storage efficiency and coverage preservation, motivating its selection for Online mode deployment. We investigate the performance implications of this filtering strategy below.

\subsubsection{Replay Mode Performance}

This subsection addresses \textbf{RQ2} and \textbf{RQ3} by evaluating Replay mode on 1,000 blocks to establish performance upper bounds under perfect path knowledge for archive node scenarios. This represents the oracle baseline where all execution paths are known deterministically.

Figure~\ref{fig:replay_speedup_dist} presents the speedup distribution. Helios achieves a median speedup of 6.60×. The distribution exhibits strong tail performance with the 75th percentile at 13.88× and the 90th percentile at 21.43×. Only 5.4\% of blocks experience slowdown relative to baseline execution. The distribution concentrates in the 5-10× range at 22.6\% and 10-20× range at 25.6\%, demonstrating consistent acceleration across diverse workloads.

Replay mode proves particularly valuable for archive nodes performing historical synchronization, where blockchain history is optimized once and replayed efficiently for subsequent queries or re-synchronizations.

\subsubsection{Online Mode Effectiveness}

This subsection addresses \textbf{RQ2} and \textbf{RQ3} by evaluating Online mode for live transaction execution where execution paths are unknown a priori. We evaluate performance on 1,000 blocks immediately following the 5,000-block warmup period, ensuring the test set contains fresh transactions not seen during cache construction. We evaluate performance under two configurations. Online mode without filtering caches all paths from the warmup period. Online mode with frequency $\geq$10 filtering retains only paths exceeding the frequency threshold, as motivated by Table~\ref{tab:storage_coverage_tradeoff}.

\noindent\textbf{Online Mode Without Filtering.}
Figure~\ref{fig:online_no_filter} presents the speedup distribution when caching all paths. Online mode achieves a median speedup of 4.56×, underperforming Replay mode's 6.60× by 31\%. The distribution concentrates in the 5-10× range at 34.0\%, with the 75th percentile at 7.12× and the 90th percentile at 9.85×. Only 8.8\% of blocks exhibit slowdown relative to baseline execution.

\noindent\textbf{Online Mode With Frequency Filtering.}
Figure~\ref{fig:online_filtered} presents the speedup distribution under frequency $\geq$10 filtering. Median speedup drops to 2.05×, representing a 55\% reduction relative to unfiltered Online mode. The distribution shifts toward lower speedup ranges, with 36.2\% of blocks concentrated in the 1-2× range. However, tail performance remains competitive at the 90th percentile with 9.01× speedup. Performance degradation primarily affects median and lower percentiles rather than tail workloads.

\noindent\textbf{Performance Degradation Analysis.}
Three factors contribute to Online mode's performance degradation relative to Replay mode. First, greedy Top-1 path selection achieves only 58.0\% hit rate under frequency $\geq$10 filtering, causing 42\% of transactions to fall back to native execution. Contracts with multiple high-frequency paths driven by input-dependent control flow cannot be fully covered by single-path caching. Second, Helios employs transaction-level rollback for path mispredictions. When a path divergence occurs during execution, the entire transaction rolls back to native execution rather than switching to an alternative path mid-execution. This all-or-nothing strategy amplifies the penalty for cache misses, as partially completed optimized execution provides no benefit. Third, per-transaction overhead from path prediction and cache lookup becomes proportionally significant when optimized paths execute in microseconds. These limitations suggest opportunities for multi-path caching, incremental rollback mechanisms, and adaptive path selection strategies, which we discuss in \S\ref{sec:discussion}.

\section{Discussion}
\label{sec:discussion}

This section interprets the performance results, analyzes the limitations of the current design, and outlines future research directions.

\subsection{Interpreting the Speedup}

Helios achieves a median speedup of 6.60$\times$ in Replay Mode. This performance improvement results from the execution of optimized SSA graphs, which eliminates redundant stack operations and simplifies gas accounting for static instructions.

However, the evaluation reveals a disparity between the opcode reduction rate and the actual execution speedup. While SSA optimization removes approximately 80\% of instructions, the microbenchmark speedups range from 1.14$\times$ to 2.00$\times$. This discrepancy indicates that the overhead of the Traced Interpreter limits the potential performance gains. The management of execution metadata and the interpretation of the graph structure introduce costs that are comparable to the savings from instruction elimination. Furthermore, unoptimized heavy instructions continue to dominate the execution time in certain workloads.

A promising direction for future work is to implement Just-In-Time (JIT) or Ahead-Of-Time (AOT) compilation. Compiling the execution logic of the Traced Interpreter into native machine code would eliminate the interpretation overhead. The register-based design of the SsaGraph facilitates this transition as it maps naturally to modern CPU architectures. This approach would allow the system to fully leverage the instruction reduction achieved by the SSA optimizer.

\subsection{Online Mode Challenges}

The performance of Online Mode exhibits a reduction when frequency-based filtering is applied. Our analysis of the coverage table reveals a gap between the coverage achieved by the Top-1 prediction strategy and the actual execution coverage. This suggests that the current simplicity-first selection strategy does not fully utilize the optimized paths.

We explored alternative strategies to address this limitation, including a race-parallel execution model. In this approach, the system caches the Top-K paths and executes them concurrently, committing the result of the first successful path or falling back to native execution if all fail. However, microbenchmarks showed that the overhead of the parallel framework outweighed the benefits. Native execution completed in 60 $\mu$s, whereas the race-parallel implementation increased latency to 70 $\mu$s, compared to 30 $\mu$s for the baseline optimized execution in the Uniswap-1hop case. Efficiently leveraging multi-path caching remains an open problem.

Another factor contributing to the performance degradation is the transaction-scoped fallback mechanism. Currently, a single frame prediction failure triggers a rollback of the entire transaction to the native EVM, resulting in the underutilization of successful frame-level predictions. A potential solution is to implement frame-level fallback, where only the failed frame reverts to native execution while subsequent frames attempt to use cached paths. To mitigate the risk of frequent engine switching, which we term "de-optimization bombs," an optimization circuit breaker could limit the number of allowed fallbacks per transaction. Furthermore, the system could explore chained predictions, where the output of one optimized frame directly triggers the speculative execution of the next. These strategies represent a trade-off between architectural simplicity and execution coverage that warrants further investigation.

\subsection{System Scalability}

Beyond execution logic, system scalability presents additional opportunities for optimization. While our initial exploration of instruction-level parallelism (ILP) did not yield satisfactory results due to synchronization overhead, the potential for parallel execution remains. The current dependency graph modeling could be enhanced by incorporating advanced ILP techniques from compiler theory. Future research could investigate more sophisticated scheduling algorithms or hardware-assisted synchronization primitives to unlock the parallelism inherent in the SsaGraph.

Finally, the current Path Cache implementation prioritizes low storage overhead with a simple persistence and pruning policy. As the system scales to handle larger state histories, more mature caching strategies will be required. Future work could explore tiered storage architectures that balance hit rate, retrieval latency, and storage cost, potentially leveraging external high-performance key-value stores for long-term artifact persistence.

\section{Related Work}

This work focuses on accelerating Ethereum Virtual Machine (EVM) execution, specifically targeting modern, high-performance interpreters such as Revm. Research in this domain can be categorized into smart contract optimization toolchains, trace-based speculative execution systems, and concurrent execution architectures.

\subsection{Smart Contract Optimization and Compilation}

Optimization in the smart contract landscape spans from static source analysis to bytecode rewriting and compilation.

\textbf{Program Analysis and Optimization.} Traditional Solidity toolchains provide static analysis capabilities that serve as a foundation for downstream optimization. Tools like Slither \cite{slither} generate intermediate representations (SlithIR) and control flow graphs (CFG) to detect vulnerabilities. Rattle \cite{rattle} lifts EVM bytecode into a Static Single Assignment (SSA) form to recover high-level control flow. While Rattle and Helios both leverage SSA to eliminate redundant stack operations, their objectives differ fundamentally. Rattle employs SSA as an intermediate representation for static analysis and decompilation, prioritizing readability without propagating changes back to the executable bytecode. In contrast, Helios utilizes SSA as a dynamic, executable format (\texttt{SsaGraph}) specifically designed for the runtime engine. The Helios optimizer operates on frame-level execution paths rather than static bytecode, generating artifacts for immediate execution acceleration via a specialized interpreter rather than for analysis.

\textbf{Superoptimization.} Superoptimization frameworks, such as \texttt{ebso} \cite{ebso} and \texttt{Gasol} \cite{gasol}, aim to identify the optimal instruction sequence functionally equivalent to a target sequence but with minimal gas cost. While theoretically capable of producing maximally efficient code, these approaches rely on SMT solvers (e.g., Z3) to verify equivalence. The operational semantics of the EVM—specifically the modeling of memory expansion, storage, and dynamic gas costs—require complex logic encodings that heavily tax SMT solvers. Consequently, the search space for equivalent programs explodes exponentially with instruction count, often necessitating strict timeouts or restricting optimization to basic blocks without memory side-effects. These constraints make superoptimization difficult to apply dynamically at runtime.

\textbf{JIT and AOT Compilation.} Just-In-Time (JIT) and Ahead-Of-Time (AOT) compilers attempt to translate EVM bytecode into native machine code. Projects like Revmc \cite{revmc} generate Rust code from EVM bytecode to bypass the interpreter loop. However, for the microsecond-scale transactions typical of the EVM, the overhead of runtime code generation often outweighs the execution speedup. Helios mitigates this overhead by avoiding full native compilation. Instead, it transforms execution paths into an abstract graph representation replayed by a specialized Traced Interpreter. This approach maintains the micro-architectural optimizations of the underlying host interpreter while reducing the instruction dispatch count.

\subsection{Trace-Based Speculative Execution}

As a path-driven execution engine, Helios is directly comparable to systems like Forerunner \cite{forerunner} and Seer \cite{seer}.

\textbf{Comparison with Existing Systems.} Forerunner applies constraint-driven speculative execution, generating "Accelerated Programs" (APs) based on transaction history. Seer employs fine-grained branch prediction and snapshots to manage state dependencies. However, these systems face limitations when applied to modern, fast interpreters due to their tracing strategy. Forerunner relies on full-context tracing, capturing stack frames, memory snapshots, and contract state. On highly optimized engines like Revm, the I/O overhead of loading these large artifacts often exceeds the execution time of the transaction itself. Helios employs \textbf{lightweight asynchronous tracing} to address this bottleneck. By recording only stack operations and minimal data dependencies, Helios achieves compression rates of 9.4$\times$ to 16.4$\times$ compared to full-context approaches, rendering online artifact management practical.

\textbf{Granularity and Gas Semantics.} Existing systems typically utilize transaction-level caching, which limits reuse to identical transaction sequences. Helios introduces \textbf{frame-level caching}, exploiting the observation that individual contract call frames exhibit high path locality even when parent transactions differ. Furthermore, prior works do not explicitly address the preservation of gas semantics during optimization. Helios guarantees gas equivalence by construction: it restricts SSA optimization to static-cost instructions while delegating all dynamic-cost operations (e.g., memory expansion, storage access) to the native EVM, ensuring the economic model remains undisturbed.

\subsection{Concurrent and Parallel Execution}

Various concurrent execution architectures address the sequential bottleneck of the EVM.

\textbf{Operation-Level Concurrency.} ParallelEVM \cite{parallelevm} (also known as Olive) enables operation-level concurrency by dynamically generating an SSA Operation Log to track data dependencies. This mechanism allows selective re-execution of conflicting operations rather than aborting entire transactions. While both ParallelEVM and Helios leverage SSA, their objectives differ fundamentally: ParallelEVM employs SSA for concurrency control and conflict resolution, whereas Helios utilizes it for single-thread execution path optimization. Furthermore, ParallelEVM relies on synchronous runtime tracing. Although the reported log generation overhead is approximately 4.5\%, Helios posits that on high-performance interpreters like Revm, any synchronous tracing on the critical path introduces non-negligible overhead, limiting net acceleration.

\textbf{Parallel Architectures.} Other approaches focus on architectural innovations. PaVM \cite{pavm} supports both intra-contract and inter-contract parallelism through a specialized runtime system, though it does not explicitly address parallel determinism. Block-STM \cite{blockstm} implements optimistic concurrency control with a collaborative scheduler to execute transaction sets in parallel. Hardware-centric solutions such as MTPU \cite{mtpu} adopt algorithm-architecture co-design, utilizing spatial-temporal scheduling to exploit parallelism.

\textbf{Orthogonality Analysis.} Helios is orthogonal to these frameworks. Its core contribution is a lightweight, high-throughput path execution engine that optimizes the fundamental unit of computation—the sequential execution of a contract path. This baseline acceleration can be integrated into parallel frameworks such as ParallelEVM, Block-STM, or PaVM to further maximize system throughput.

\subsection{Alternative Virtual Machine Environments}

The emergence of WebAssembly (WASM) in blockchain has led to new runtime environments like DTVM \cite{dtvm} and Wasmtime, which utilize JIT compilation and "hot-switching" mechanisms to balance startup performance with long-term execution efficiency. Helios adopts a similar philosophy for the EVM, using a dual-mode approach (Online vs. Replay) to adaptively balance the overhead of tracing against the benefits of optimized execution.

\section{Conclusion}

We presented Helios, a path-driven execution engine designed to accelerate transaction processing on high-performance EVM clients. We identified a \textit{performance paradox} in existing optimization strategies: on modern, highly optimized interpreters, the overhead of detailed tracing and artifact management often negates the benefits of optimization. Helios addresses this challenge through a novel architecture that combines lightweight asynchronous tracing with frame-level caching. By restricting optimization to static-cost instructions, Helios achieves gas-semantic equivalence by construction, eliminating the economic risks associated with aggressive JIT compilation.

Our evaluation on Ethereum mainnet workloads demonstrates the efficacy of this approach. In Replay Mode, Helios achieves a median speedup of 6.60$\times$ over the baseline Revm interpreter, validating its potential for accelerating archive node synchronization and historical data analysis. In Online Mode, Helios effectively accelerates hot execution paths with modest storage overhead, leveraging the strong path locality inherent in smart contract execution.

Helios establishes a new design point for blockchain execution engines, prioritizing safety, correctness, and architectural simplicity alongside raw performance. Future work will explore integrating Just-In-Time (JIT) compilation to further reduce interpretation overhead for optimized paths and refining the speculative execution model with frame-level fallback mechanisms to maximize coverage. By decoupling optimization from the critical path, Helios provides a scalable foundation for the next generation of EVM infrastructure.