\section{Motivation}

Traditional path-driven optimization systems like Forerunner and Seer achieve 5–8× speedups on classical EVM interpreters such as Geth. However, when applied to modern, highly-optimized implementations like Revm, these gains diminish sharply---speedups drop from 5.0× on Geth to only 1.5× on Revm for identical bytecode. This degradation exposes fundamental limitations in existing optimization strategies when baseline execution is already fast. Through systematic analysis across four critical design dimensions---optimization paradigm, tracing strategy, artifact organization, and correctness guarantees---we derive a set of principled design choices that enable effective optimization on modern EVMs. Each choice addresses specific bottlenecks while establishing constraints that guide subsequent decisions, ultimately converging on Helios's architecture.

\subsection{The Performance Paradox of Full Tracing}
\label{sec:performance-paradox}

A foundational assumption of prior work is that the overhead of detailed tracing is a worthwhile price for enabling powerful optimizations. While this holds true on traditional interpreters, our analysis reveals that on modern, highly-optimized EVMs, this assumption breaks down. The overhead of full tracing—which records all stack, memory, and storage dependencies—transforms from a minor factor into the primary performance bottleneck.

This performance paradox is most evident in the I/O cost of the optimization artifacts themselves. For a single Uniswap V2 swap, a full trace generates approximately 900 KB of data. While loading and parsing this artifact is negligible when baseline execution takes hundreds of microseconds, it becomes a dominant cost when an interpreter like Revm executes each opcode in just 16–31 nanoseconds. At this speed, the time spent on memory I/O to process the trace is comparable to the computational work being optimized, severely diminishing the net performance gain.<这里引用bench set>

One might consider online tracing to mitigate this I/O overhead, but this introduces prohibitive CPU costs. Instrumenting Revm with a full online tracer increased single-transaction latency from 60 µs to over 180 µs—a 3× slowdown on the critical path. This overhead stems from per-opcode hook invocations, shadow data structure maintenance, and context switches, all of which are magnified when the baseline execution is already extremely fast. Even when employing 8-thread parallelism, the end-to-end block processing time merely matched that of the unoptimized serial execution, yielding no net benefit. <或许需要一个数据展示>

Finally, even if we were to accept these high overheads, the primary benefit promised by full tracing—the potential for instruction-level parallelism—proves to be illusory in practice. We implemented a dependency-graph-driven parallel executor for Revm, scheduling independent opcodes across multiple threads. Contrary to theoretical models, the parallel version was consistently slower than its optimized serial counterpart. The root cause is fundamental: at a nanosecond granularity of computation, the cost of thread synchronization and communication far exceeds the execution time of the instructions being parallelized, invalidating the core assumption of negligible synchronization overhead. <或许需要一个数据展示>

These findings converge on a single, critical insight: on modern EVMs, the cost of the analysis itself has become the dominant barrier to performance. This leads to our first design principle:

\noindent\textbf{Design Principle 1:} Minimize analysis overhead through lightweight, asynchronous tracing. To achieve meaningful speedups, an optimization strategy must: (1) produce compact artifacts to minimize I/O costs; (2) operate asynchronously and off the critical execution path; and (3) capture only the information that enables practical, low-overhead optimizations.


\subsection{Untapped Value of Path Locality}
\label{sec:path-locality}

Forerunner and Seer adopt per-transaction optimization, where each transaction's artifacts are generated and discarded immediately after use. Even when two transactions invoke identical contract functions along identical paths, the system repeats the full tracing and optimization process. Given that \S\ref{sec:dual-overhead} established the high cost of these operations on modern implementations, this "use-once-discard" model represents significant wasted effort.

We quantify this waste through large-scale path analysis on Ethereum mainnet, analyzing blocks XXX–XXX with N blocks and M transactions. By hashing execution paths per contract frame and tracking frequency, we observe a pronounced Pareto distribution. The top 10\% of unique paths account for over 90\% of executions. Further decomposition shows the top 1\% handle 60\% of executions and the top 5\% handle 80\%. This distribution remains stable across different block ranges, indicating that execution exhibits strong path locality as a fundamental characteristic rather than transient behavior.

This finding reveals an untapped optimization opportunity. A persistent, cross-transaction cache would amortize tracing costs across hundreds or thousands of subsequent executions. For high-frequency paths, the optimization overhead becomes negligible when amortized, fundamentally changing the cost-benefit ratio. Rather than merely reducing per-optimization absolute cost (Principle 1), we can also reduce average cost through reuse.

This empirical analysis exposes a key deficiency in per-transaction models. They ignore temporal reuse patterns, leading to redundant analysis work. Path locality motivates our second principle:

\noindent\textbf{Design Principle 2:} Enable cross-transaction reuse through persistent caching. Optimization artifacts represent long-term value and should be indexed, stored, and reused across transactions to amortize costs and exploit path locality.

\subsection{Frame-Level Path-Driven Optimization}
\label{sec:frame-level-optimization}

The previous sections established the need for lightweight tracing and cache reuse, but two design questions remain. First, what to trace as the scope. Second, at what granularity to organize artifacts as the caching unit. This section analyzes these dimensions and shows how frame-level, path-driven, stack-only optimization simultaneously satisfies Principles 1 and 2 while naturally preserving gas-semantic equivalence.

\subsubsection{Tracing Scope: Stack-Only vs. Full}
\label{sec:tracing-scope}

Full tracing of stack, memory, and storage produces 900 KB artifacts with significant I/O overhead as shown in \S\ref{sec:artifact-overhead}. We propose a more aggressive simplification by tracing only stack operations and completely omitting memory and storage. EVM's execution profile justifies this choice. Stack operations dominate instruction counts, while memory and storage accesses are relatively rare. More critically, these rare access instructions form "side-effect boundaries" that optimizers must conservatively preserve; removing them would violate gas semantics by altering dynamic cost calculations.

Despite omitting memory/storage tracking, Helios achieves 2.3× speedup on Revm. While lower than Forerunner's 5.0× on Geth, this must be contextualized. Revm's native execution is already 6.7× faster than Geth, and \S\ref{sec:artifact-overhead} identified artifact overhead as a limiting factor. The result suggests stack-only tracing captures substantial optimization headroom in our workloads. This is likely because EVM's performance bottlenecks center on frequent stack manipulation and indirect addressing, while memory and storage accesses, though semantically important, constitute a smaller fraction of execution time and are already heavily optimized in modern implementations.

\subsubsection{Optimization Granularity: Contract-Level vs. Path-Driven vs. Frame-Level}
\label{sec:optimization-granularity}

Contract-level optimization, such as JIT compilers, treats entire contracts as compilation units, enabling global optimization across functions and basic blocks. However, this approach faces two critical challenges. First, security concerns arise because malicious contracts can trigger "JIT Bomb" DoS attacks via pathological bytecode patterns, forcing whitelist-only deployment that limits applicability. Second, gas semantics become problematic when aggressive transformations such as loop invariant hoisting and dead code elimination remove or reorder opcodes with dynamic gas costs, creating divergence from native execution that undermines economic incentives when miners' costs no longer match collected fees.

Path-driven optimization offers a safer alternative by optimizing only actually-executed paths rather than entire contracts. This inherently bounds optimization costs per path, eliminating JIT Bomb vulnerabilities and enabling universal deployment without whitelists. However, path-driven systems must still address gas-semantic preservation explicitly. Helios achieves this through specific design choices detailed in \S\ref{sec:gas-semantic-equivalence}, while other systems such as Forerunner and Seer do not explicitly discuss this equivalence.

Within path-driven paradigms, a critical granularity choice emerges between transaction-level and frame-level artifact organization. Transaction-level systems such as Forerunner and Seer generate monolithic artifacts covering all contract frames in a transaction, recording opcodes in flat log sequences with implicit frame boundaries via Log Sequence Numbers. This introduces two problems. First, it requires custom frame management logic rather than leveraging host EVM infrastructure. Second, it severely limits reuse potential. Consider three transactions: Tx1 calls C1→C2, Tx2 calls C3→C4, and Tx3 calls C1→C3. Under transaction-level organization, Tx3 cannot reuse cached artifacts from Tx1 or Tx2 despite sharing individual frames. The cache key is the entire transaction's execution pattern, not individual frame paths.

Frame-level organization treats each contract call frame as an independent optimization unit, generating and indexing artifacts per frame. In the Tx3 example, although the call sequence C1→C3 is novel, the constituent frames likely appeared in Tx1 and Tx2 respectively. Specifically, C1 invocation and C3 invocation can be reused. Frame-level systems recognize and reuse these cached frame paths, performing new tracing only for genuinely unseen execution paths. This compositional reuse significantly increases effective cache coverage, achieving higher hit rates with equivalent storage overhead.

Furthermore, frame-level granularity aligns naturally with EVM's execution model as detailed in \S\ref{sec:evm-model}, % TODO: add label to Background section
which inherently manages resources and state at frame boundaries. This alignment allows direct reuse of mature frame management infrastructure from host clients, including optimized memory allocation and storage access patterns, avoiding the complexity and overhead of custom frame simulation required by transaction-level approaches.

Frame-level path-driven optimization demonstrates advantages across three dimensions. It avoids JIT Bomb attacks for security, enables compositional caching for reuse efficiency, and leverages host infrastructure to reduce engineering complexity. \S\ref{sec:cache-hit-rates} % TODO: add label to Evaluation section
will quantify cache hit rate improvements from frame-level decomposition; \S\ref{sec:performance-comparison} % TODO: add label to Evaluation section
will compare path-driven versus JIT performance on hot paths.

\subsubsection{Gas-Semantic Equivalence as an Emergent Property}
\label{sec:gas-semantic-equivalence}

In Ethereum's economic model, gas underpins miner incentives because transaction senders pay fees proportional to gas consumed. Any optimization altering gas consumption disrupts this balance. If optimized execution consumes fewer resources but charges original gas amounts, miners receive excess compensation. Conversely, undercharging may prompt miners to disable optimization. Maintaining gas-semantic equivalence, which means exact matching of native execution's gas accounting, is thus critical for practical adoption.

Our stack-only tracing choice from \S\ref{sec:tracing-scope} naturally sidesteps dynamic gas complexity. Nearly all dynamically-costed instructions involve memory or storage operations. These instructions have runtime-dependent gas consumption, such as MLOAD where cost scales with memory expansion, or SLOAD where cost depends on access history. By excluding these from optimization artifacts, we ensure they remain processed natively by the host EVM with precise accounting. The optimizer completely avoids dynamic gas calculation complexity.

Conversely, optimized instructions have static costs determinable at compile time. These include eliminated redundant DUP/SWAP operations and constant-folded arithmetic. Although physically removed or merged during execution, their cumulative static gas can be precomputed and deducted in bulk, maintaining total accuracy while reducing per-instruction accounting overhead. This is detailed in \S\ref{sec:gas-chunk} % TODO: add label to Implementation section
as the GasChunk mechanism.

Frame-level granularity from \S\ref{sec:optimization-granularity} further reinforces gas preservation. EVM's gas accounting itself operates at frame boundaries. Each frame receives a gas quota at creation, consumes it during execution, and returns the remainder to its parent on exit. Aligning optimization boundaries with gas accounting boundaries ensures each frame's gas flow matches native execution exactly, avoiding complexity from cross-frame gas aggregation or redistribution.

Contract-level JIT faces a tradeoff here. Aggressive global optimizations such as loop hoisting and block merging can alter gas consumption patterns. Preserving gas equivalence requires disabling or constraining such transformations, shrinking the optimization space and potentially reducing performance gains. In contrast, stack-operation-based path-driven optimization avoids this tradeoff. By excluding memory and storage operations, the optimization scope is naturally limited to statically-costed instructions whose gas can be precisely preserved. The optimizer can freely eliminate redundant stack operations and perform constant folding without compromising between "optimization aggressiveness" and "gas preservation."

The convergence of three design choices produces an important emergent property. These choices are stack-only tracing, frame-level organization, and path-driven optimization. Together, they yield precise gas-semantic equivalence. This equivalence requires no compensatory mechanisms but arises naturally from the interplay of multiple constraints. This enables our third principle:

\noindent\textbf{Design Principle 3:} Achieve multiple objectives through frame-level, path-driven, stack-only optimization. By selecting appropriate scope and granularity, the system simultaneously attains three goals. First, deep optimization of hot paths. Second, compositional artifact reuse across transactions. Third, exact gas-semantic preservation. These three goals are difficult to reconcile in traditional contract-level or transaction-level paradigms.

\subsection{Synthesis: From Principles to System Architecture}
\label{sec:synthesis}

The three design principles map directly to architectural decisions. Principle 1 on lightweight and asynchronous tracing drives two core components: a selective hook-based tracer capturing only stack dependencies, and an asynchronous, pipelined artifact generation mechanism. Principle 2 on cross-transaction reuse necessitates a multi-tier cache architecture with per-frame-path indexing, supporting both deterministic lookup for known path IDs and speculative querying for predicted hot paths.  Principle 3 on frame-level and stack-only optimization requires fine-grained control over execution mode selection at the frame granularity. Rather than following a fixed execution sequence, the system must flexibly choose between optimized and native execution for each individual frame based on runtime conditions. This flexibility requirement, combined with the locality property from Principle 2, motivates the design of dual-mode execution, particularly the Online mode. The optimized engine handles cached paths by converting the stack machine model to a register model with chunked gas accounting, while seamlessly falling back to native interpretation when cache misses occur or validation fails.

These design choices manifest differently across node workloads. Archive nodes perform deterministic historical replay where all execution paths are known and unchanging. This enables Replay mode by pre-populating the cache to achieve 100\% hit rates, exploiting Principle 2 to the fullest. Single tracing costs are amortized across thousands of replays, yielding approximately 5× average speedup with ~10\% storage overhead. Full nodes handle unpredictable live transactions. This requires Online mode where background tracing from Principle 1 captures paths without blocking transactions, dynamic caching from Principle 2 maintains hot-path coverage, and speculative execution from Principle 3 accelerates cache hits while falling back on misses. This achieves approximately 2× average speedup covering ~50\% of contract calls with ~5\% storage overhead.

Both modes share identical core components and artifact formats. They differ only in cache population strategy, either pre-fill or on-demand, and execution strategy, either deterministic or speculative. This unified design allows a single implementation to span the full node-type spectrum.

Building on these three design principles and their application across scenarios, we present Helios. This system's architecture and implementation are detailed in the following section.