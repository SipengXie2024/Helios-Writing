\section{Background \& Motivation}
\label{sec:background_motivation}

\subsection{The EVM Execution Model}
\input{figures/evm-workflow}

The Ethereum Virtual Machine operates as a quasi-Turing-complete stack machine~\cite{ethereum}. Unlike register-based architectures, the EVM performs all computations on a transient runtime stack using manipulation instructions such as DUP and SWAP to manage operand placement. This design necessitates frequent stack operations that incur significant execution overhead.

Execution is compartmentalized into a hierarchy of call frames. Each frame maintains an isolated memory context and stack while sharing persistent storage access with other frames in the transaction. Resource consumption is metered via gas, which functions as both a validator incentive and a security mechanism against denial-of-service attacks. Gas costs fall into two distinct categories. Static costs are fixed at compile time for computational operations such as arithmetic and stack manipulation. Dynamic costs depend on runtime state, including memory expansion extent and storage access frequency. This distinction is fundamental to our design, as it enables optimization strategies that aggregate static costs while delegating dynamic accounting to native handling logic.

The EVM specification includes a standard hook mechanism to facilitate debugging and tracing. As illustrated in Figure~\ref{fig:evm-workflow}, this interface triggers events at key lifecycle points such as opcode execution and frame transitions. This design enables external components to passively observe execution states and capture data dependencies without requiring invasive modifications to the core interpreter logic.

\subsection{Ethereum Node Workloads}

The Ethereum network depends on node archetypes that exhibit divergent operational characteristics~\cite{eth-nodes-and-clients}. Full nodes operate within fixed block intervals and prioritize the low-latency processing of unpredictable transactions to maintain consensus stability. Archive nodes maintain comprehensive ledger history and emphasize execution throughput to facilitate bulk re-execution of historical states~\cite{geth-sync-modes, eth-archive-node, feng2024slimarchive}.

This operational dichotomy has direct implications for execution acceleration. Full nodes operate in an online mode where execution paths are unknown prior to invocation, precluding ahead-of-time compilation. Acceleration in this context demands minimal response latency while simultaneously generating optimization artifacts for future reuse. Archive nodes operate in a replay mode where execution paths are deterministic and known in advance, enabling aggressive precomputation. Acceleration in this context demands maximum throughput by leveraging cached artifacts across millions of historical transactions. Any unified acceleration framework must therefore accommodate both modes, balancing low-latency responsiveness with high-throughput batch processing.

\subsection{Limitations of Contract-Level Optimization}

Contract-level optimization, exemplified by JIT compilation, faces two critical limitations in permissionless blockchain environments. \textbf{First}, JIT compilation introduces security vulnerabilities. Attackers can construct pathological code patterns, such as deeply nested conditional branches, to trigger exponential compilation complexity. This computational asymmetry allows malicious actors to exhaust validator resources via low-gas transactions, constituting a denial-of-service vector known as JIT bombs~\cite{revmc,monad,evmjit,bnbjit,JITBomb}. \textbf{Second}, JIT compilation risks gas-semantic discrepancies. Aggressive compiler optimizations such as instruction reordering and dead code elimination alter the observable execution trace, violating the strict gas accounting rules that underpin economic consensus. Any systematic deviation from the canonical gas schedule results in incorrect validator compensation and impedes the deployment of production clients~\cite{revmc,monad}.

These constraints suggest that contract-level compilation faces significant challenges in permissionless execution environments. Path-driven optimization emerges as a safer paradigm by restricting acceleration to actually executed paths, thereby bounding optimization costs to the runtime trace and inherently avoiding dead code and unreachable branches. However, existing path-driven approaches encounter their own scalability barriers on modern execution engines.

\subsection{The Performance Paradox}
\input{table/motivation-overhead}

Existing path-driven schemes face a phenomenon we term the \textit{Performance Paradox}. On slower engines such as Geth~\cite{geth}, transaction execution dominates end-to-end latency, rendering additional instrumentation costs negligible. A prior path-driven system~\cite{forerunner} achieves a 5.8$\times$ speedup on Geth. However, on highly optimized engines such as Revm~\cite{revm}, execution becomes inexpensive and auxiliary overhead emerges as the primary bottleneck. The same system achieves a more modest 1.6$\times$ on Revm. Table~\ref{tab:motivation-overhead} quantifies this shift using a representative Uniswap V2 swap transaction~\cite{uniswapv2}.

Three categories of auxiliary overhead contribute to this paradox. \textbf{First}, synchronous tracing dominates the critical path. On Revm, capturing full execution state is approximately six times slower than native execution and nearly ten times slower than optimized execution. Any synchronous instrumentation on the critical path effectively negates the speedup from optimization. \textbf{Second}, artifact management incurs substantial fixed costs. Loading and parsing a 663\,KB artifact to accelerate a task completing in tens of microseconds introduces I/O latency that does not scale with execution time. \textbf{Third}, fine-grained concurrency yields limited benefits. We implemented a dependency-graph-driven parallel executor on Revm to evaluate instruction-level parallelism. As shown in Table~\ref{tab:motivation-overhead}, this approach achieves approximately 0.2$\times$ the throughput of sequential execution. The root cause is granularity mismatch. Individual opcode execution requires approximately 20 nanoseconds, while thread synchronization and context switching require hundreds of nanoseconds~\cite{parallelEvm,evmTracer}. Coordination overhead consistently exceeds parallel gains at this granularity.

These observations collectively suggest that synchronous tracing, heavyweight artifacts, and fine-grained parallelism present significant challenges for high-performance execution engines. Effective acceleration requires asynchronous optimization decoupled from the critical path, lightweight trace representations, and sequential execution of optimized code.

\subsection{The Granularity Mismatch}
\input{figures/pareto-cumulative}

Beyond auxiliary overhead, existing path-driven strategies employ transaction-level caching~\cite{forerunner,seer,parallelEvm}, treating the entire execution trace as the atomic optimization unit. This granularity creates a combinatorial challenge where slight variations in call sequences invalidate cached artifacts, often resulting in a use-once-discard lifecycle that limits reuse.

Our analysis of Ethereum mainnet workloads reveals significant redundancy at finer granularity. As shown in Figure~\ref{fig:pareto-cumulative}, unique frame-level paths follow a Pareto distribution where the top 1\% accounts for over 70\% of total execution time. While unique transaction combinations are vast, individual contract calls function as repetitive building blocks. Shifting the optimization unit from transactions to frames exploits this locality and amortizes compilation costs across thousands of invocations.

\subsection{Design Implications}

The preceding analysis establishes three architectural principles for high-performance EVM acceleration. \textbf{First}, the distinction between static and dynamic gas costs motivates a hybrid execution model. Restricting optimization to static-cost instructions while delegating dynamic operations to native handling ensures gas-semantic equivalence by construction. \textbf{Second}, the Performance Paradox necessitates asynchronous lightweight tracing. Decoupling trace generation from the critical path and minimizing trace volume preserves baseline execution speed while enabling background optimization. \textbf{Third}, pronounced frame-level locality motivates persistent caching at this granularity. Frame-level artifacts enable compositional reuse across diverse transactions, overcoming the ephemeral nature of transaction-level approaches. These principles collectively inform the design of Helios.
