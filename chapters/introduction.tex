\section{Introduction}

Ethereum and other EVM-compatible blockchains rely on general-purpose virtual machines to execute smart contracts. As transaction throughput and contract complexity increase, execution becomes a primary scalability bottleneck for both full and archive nodes. While consensus and data availability layers have scaled significantly, the sequential execution of complex smart contracts remains a limiting factor for network performance.

To address this bottleneck, recent research has explored various optimization strategies, ranging from Just-In-Time (JIT) compilation to path-driven speculative execution. Systems such as Forerunner and Seer~\cite{forerunner, seer} record detailed transaction-level traces or maintain substantial shadow state to guide speculative reuse, while EVMTracer and ParallelEVM~\cite{evmTracer,parallelEvm} exploit operation-level parallelism. However, these approaches face an inherent trade-off when applied to modern, highly optimized EVM interpreters such as Revm. We refer to this trade-off as a \textit{performance paradox}: when the baseline EVM is already highly optimized, the overhead of tracing, analysis, and artifact management can outweigh the benefits of optimization. Contract-driven JIT approaches~\cite{revmc}, while theoretically powerful, introduce security risks such as JIT bombs and complicate the maintenance of gas-semantic equivalence. Conversely, traditional path-driven approaches incur significant memory I/O and analysis overhead. On fast interpreters where baseline execution completes in microseconds, the cost of loading and processing large trace artifacts often exceeds the execution time itself.

This challenge necessitates a path-driven execution engine that remains safe and gas-precise, yet lightweight enough to deliver net gains on top of modern EVM interpreters. A key observation is that existing systems operate at a suboptimal granularity. Transaction-level caching fails to exploit the repetition of individual contract calls across different transactions, while full-state tracing captures far more information than is necessary for effective optimization.

In this paper, we present Helios, a lightweight, path-driven execution engine designed for high-performance EVM clients. Helios addresses the performance paradox through three core design principles. First, it employs \textit{lightweight asynchronous tracing} that records only stack operations and minimal data dependencies, avoiding the overhead of shadowing full EVM state. This tracing runs off the critical path, so that optimization does not delay live execution. Second, Helios implements \textit{frame-level caching}. We observe that call frames exhibit strong path locality across transactions, so that a relatively small set of cached paths can cover a large fraction of execution. By caching optimized paths at the frame level rather than the transaction level, Helios achieves effective reuse with modest storage overhead. Third, by restricting optimizations to static-cost instructions and delegating all dynamic-cost operations to the underlying EVM, Helios preserves gas semantics by construction, without requiring complex compensation logic.

Helios operates in two distinct modes to support diverse node workloads. In \textit{Replay Mode}, targeted at archive nodes, it leverages pre-computed paths to accelerate historical block processing with no speculation overhead. In \textit{Online Mode}, targeted at full nodes, it employs a simple frequency-based mechanism to speculatively optimize hot paths in real time while falling back to the native interpreter on mispredictions.

We make the following contributions:

\begin{itemize}
    \item \textbf{Problem Analysis and Design Insight.} We analyze why existing JIT- and trace-based EVM optimizers struggle to deliver net gains on top of modern interpreters, and identify frame-level reuse with lightweight tracing as a viable design point. We show that a small fraction of frame-level paths accounts for the majority of execution time on mainnet workloads.
    \item \textbf{System Design.} We design and implement Helios, an execution engine that decouples tracing, optimization, and execution. Our architecture integrates with existing EVM clients, leveraging their native state management while accelerating computational logic through an SSA-based optimizer.
    \item \textbf{Evaluation.} We evaluate Helios on Ethereum mainnet workloads. In Replay Mode, Helios achieves a median speedup of 6.60$\times$ over the baseline Revm interpreter. In Online Mode, a frequency-based filter yields net speedups on hot blocks while keeping the storage footprint in the kilobyte range per contract. Our SSA optimizer eliminates a large fraction of stack and arithmetic instructions on hot paths, which contributes to these throughput gains.
\end{itemize}

The rest of this paper is organized as follows. We provide background on EVM execution and prior optimization approaches in \S\ref{sec:background}, then motivate the design of Helios in \S\ref{sec:motivation}. We present the system design in \S\ref{sec:design}, evaluate Helios on microbenchmarks and mainnet workloads in \S\ref{sec:evaluation}, and discuss implications and future directions in \S\ref{sec:discussion}.
