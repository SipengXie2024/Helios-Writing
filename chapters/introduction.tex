\section{Introduction}

Smart contract platforms~\cite{smart_contract_1,smart_contract_2,smart_contract_3} have extended blockchain functionality far beyond cryptocurrency transfers, enabling decentralized finance~\cite{defi}, non-fungible tokens~\cite{nft}, and on-chain governance~\cite{DAO}. At the core of this ecosystem lies the Ethereum Virtual Machine, or EVM, a shared execution layer that powers Ethereum mainnet, Layer-2 rollups, and EVM-compatible sidechains~\cite{ethereum,base,arbitrum,polygon,bsc}. Together, these systems secure assets worth tens of billions of dollars and process the majority of programmable on-chain activity~\cite{defillama}. 

They typically follow a Dissemination–Consensus–Execution pipeline~\cite{forerunner}, in which transactions are broadcast through a peer-to-peer network, ordered into blocks by a consensus protocol, and executed by the EVM on every node to update local state. Because each node must independently re-execute every transaction to verify state transitions, the cost of EVM bytecode interpretation is amplified across thousands of replicas. 

A node keeps pace with the chain only if it completes per-block execution within the block interval, and throughput is therefore bounded by the slower of block production and block execution~\cite{mtpu,morphDAG}. Consensus-layer advances have progressively shortened block intervals~\cite{hotstuff,parbft,tockcuckoo,tockowl}, shifting the bottleneck toward execution. Attempts to compensate by raising gas limits or packing more transactions per block~\cite{bnb_doc,poly_doc} only intensify execution pressure, inflating per-block latency and ultimately capping achievable throughput. EVM execution has thus become the dominant scalability constraint, particularly for contract-intensive workloads. 

From a data-management perspective, the EVM instantiates a deterministic transaction processor on every node that must sustain two workloads, namely real-time processing of incoming transactions and high-throughput replay of historical transactions for state verification and rollup proving. Because all nodes must agree on state transitions and gas metering underpins both economic consensus and DoS resistance, any viable acceleration strategy must improve execution speed while strictly preserving gas-semantic correctness and cross-replica determinism.

Achieving meaningful acceleration on modern, hyper-optimized execution engines~\cite{revm,evmone} involves overcoming three fundamental tensions. \textbf{First}, the \textit{Compilation Limitation}, where standard compiler optimizations can alter observable execution traces, violating gas accounting rules and introducing security vulnerabilities exploitable for denial-of-service attacks~\cite{revmc,monad,evmjit,bnbjit,JITBomb}. \textbf{Second}, the \textit{Optimization Dilemma} arises because instrumentation overhead on sub-microsecond engines frequently exceeds execution latency, while fine-grained parallelism incurs synchronization costs that often outweigh gains~\cite{forerunner,seer,parallelEvm,evmTracer}. \textbf{Third}, the \textit{Granularity Mismatch}, where transaction-level caching is susceptible to combinatorial path explosion, often resulting in ephemeral artifacts with limited reuse potential~\cite{forerunner,seer}.

To assess whether these barriers can be surmounted, we analyzed Ethereum mainnet workloads and derived three critical insights. \textbf{First}, fixed-cost computational instructions dominate hot paths, while dynamic state-access operations remain sparse~\cite{opcode1,opcode2}. \textbf{Second}, optimization-relevant dependencies are largely confined to stack operations; lightweight stack-only tracing suffices. \textbf{Third}, frame-level paths exhibit Pareto-like locality, with a small fraction of unique paths dominating total execution time.

Guided by these insights, we present Helios, a path-driven execution accelerator. Helios is built on three architectural principles, namely \textit{hybrid execution} that restricts optimization to static-cost instructions while delegating dynamic operations to the native engine, \textit{asynchronous lightweight tracing} that decouples profiling from the critical path, and \textit{frame-level caching} that exploits execution locality for high reuse. This unified architecture serves both latency-sensitive validators in Online Mode and throughput-oriented archive nodes in Replay Mode.

Realizing this architecture requires addressing two additional challenges, namely \textit{path divergence} when runtime conditions differ from profiled traces, and \textit{cache-flooding attacks} from adversarially generated paths. Helios mitigates these risks through \textit{control-flow guards} that detect divergence and trigger native fallback, and \textit{frequency-based filtering} that admits only statistically significant paths into the acceleration pipeline.

In summary, this paper makes the following contributions:
\begin{itemize}[leftmargin=0pt, itemindent=2em, labelsep=0.5em]

\item We identify the \textit{Optimization Dilemma} on modern execution engines and propose \textbf{asynchronous lightweight tracing} that decouples trace generation from the critical path, addressing the overhead barrier without blocking execution.

\item We design \textbf{frame-level caching with frequency-based filtering} that exploits execution locality to transform ephemeral artifacts into reusable components while providing inherent resistance to path-explosion attacks.

\item We develop a \textbf{guarded register-based interpreter} that accelerates execution through direct data access and bulk gas deduction, while runtime control-flow guards ensure semantic equivalence with the native engine.

\item We implement Helios on Revm and demonstrate its \textbf{architectural versatility}, achieving 6.60$\times$ median speedup in Replay Mode and 2$\times$ acceleration in Online Mode for real-time validation.

\end{itemize}

Taken together, Helios advances the state of the art along four dimensions. \textit{Safety}: hybrid execution preserves gas-semantic equivalence by construction, addressing a challenge that has limited JIT and superoptimization approaches. \textit{Efficiency}: asynchronous tracing resolves the optimization dilemma, while the guarded register-based interpreter achieves 6.6$\times$ median speedup on the already highly optimized Revm. \textit{Robustness}: control-flow guards and frequency filtering protect against path divergence and cache-flooding attacks. \textit{Versatility}: a dual-mode architecture unifies the acceleration landscape, serving both latency-sensitive validators and throughput-oriented archive nodes within a single framework.
