\section{Introduction}

Smart contract platforms~\cite{smart_contract_1,smart_contract_2,smart_contract_3,smart_contract_4} have extended blockchain functionality far beyond cryptocurrency transfers, enabling decentralized finance~\cite{defi}, non-fungible tokens~\cite{nft}, and on-chain governance~\cite{DAO}. At the core of this ecosystem lies the Ethereum Virtual Machine, or EVM, a shared execution layer that powers Ethereum mainnet, Layer-2 rollups, and EVM-compatible sidechains~\cite{ethereum,base,arbitrum,polygon,bsc}. Together, these systems secure assets worth tens of billions of dollars and process the majority of programmable on-chain activity~\cite{defillama}. 

They typically follow a Dissemination–Consensus–Execution pipeline~\cite{forerunner}, in which transactions are broadcast through a peer-to-peer network, ordered into blocks by a consensus protocol, and executed by the EVM on every node to update local state. Because each node must independently re-execute every transaction to verify state transitions, the cost of EVM bytecode interpretation is amplified across thousands of replicas. 

A node keeps pace with the chain only if it completes per-block execution within the block interval, and throughput is therefore bounded by the slower of block production and block execution~\cite{mtpu,morphDAG}. Consensus-layer advances have progressively shortened block intervals~\cite{hotstuff,parbft,tockcuckoo,tockowl}, shifting the bottleneck toward execution. Attempts to compensate by raising gas limits or packing more transactions per block~\cite{bnb_doc,poly_doc} only intensify execution pressure, inflating per-block latency and ultimately capping achievable throughput. EVM execution has thus become the dominant scalability constraint, particularly for contract-intensive workloads. 

From a data-management perspective, the EVM instantiates a deterministic transaction processor on every node that must sustain two workloads, namely real-time processing of incoming transactions and high-throughput replay of historical transactions for state verification and rollup proving. Because all nodes must agree on state transitions and gas metering underpins both economic consensus and DoS resistance, any viable acceleration strategy must improve execution speed while strictly preserving gas-semantic correctness and cross-replica determinism.

Achieving meaningful acceleration on modern, hyper-optimized execution engines~\cite{revm,evmone} requires overcoming three fundamental tensions. \textbf{First}, optimization conflicts with semantic preservation. Standard compiler optimizations such as instruction reordering inherently alter the observable execution trace, violating the strict gas accounting rules that underpin economic consensus~\cite{revmc,monad,evmjit,bnbjit}. A single gas discrepancy can cause nodes to diverge on state validity. Moreover, Just-In-Time (JIT) compilation introduces security vulnerabilities where maliciously crafted contracts exploit compilation overhead to mount denial-of-service attacks~\cite{JITBomb}. These constraints demand that any viable acceleration strategy preserve gas semantics by construction. \textbf{Second}, instrumentation overhead conflicts with execution latency. On sub-microsecond engines such as Revm~\cite{revm}, the cost of synchronous tracing frequently exceeds execution latency itself, creating what we term the \textit{Optimization Dilemma}~\cite{forerunner,seer}. Similarly, operation-level concurrent execution incurs synchronization costs that outweigh parallel gains~\cite{parallelEvm,evmTracer}. Any optimization blocking the critical path risks performance regression. \textbf{Third}, artifact granularity conflicts with reuse capability. Transaction-level caching faces combinatorial path explosion challenges, as the space of possible paths grows exponentially with contract complexity. This often results in ephemeral artifacts with limited reuse potential across diverse workloads~\cite{forerunner,seer}.

To assess whether these barriers can be surmounted, we analyzed Ethereum mainnet workloads and derived three critical insights. \textbf{First}, fixed-cost computational instructions dominate hot paths, while dynamic state-access operations remain sparse~\cite{opcode1,opcode2}. Restricting acceleration to static-cost instructions therefore enables correctness by construction, since optimizing dynamic operations risks altering the gas schedule. \textbf{Second}, optimization-relevant dependencies are largely confined to stack operations. Capturing full memory and storage state incurs prohibitive overhead yet provides negligible utility; lightweight stack-only tracing suffices. \textbf{Third}, the top 1\% of unique frame-level paths accounts for over 70\% of total execution time. Shifting granularity from transactions to call frames thus unlocks high cache hit rates across diverse workloads.

Guided by these insights, we present Helios, a path-driven execution accelerator built on three architectural principles. To preserve safety, Helios employs a hybrid execution model that restricts optimization to static-cost instructions while delegating dynamic-cost operations to the native engine, thereby preserving exact gas semantics by construction. To resolve the optimization dilemma, which arises because synchronous instrumentation on sub-microsecond engines inevitably blocks the critical path, Helios decouples trace generation from execution via asynchronous lightweight tracing that captures only stack-level dependencies. To maximize reuse, Helios organizes artifacts at frame-level granularity, enabling diverse transactions to composably reuse cached paths and converting ephemeral caching into durable components. Frame-level organization also unifies the acceleration paradigm, allowing the same cached artifacts to serve as a predictive accelerator for latency-sensitive validators in Online Mode and as a deterministic processor for throughput-oriented historical replay in Replay Mode.

Realizing this architecture demands both performance optimization and robustness against adversarial conditions. To implement hybrid execution, Helios transforms hot paths into a register-based intermediate representation that separates static instructions for compiled acceleration from dynamic instructions for native fallback. This representation eliminates redundant stack operations for direct data access and enables bulk gas deduction across static instruction sequences. Hot-path execution, however, introduces two risks requiring explicit mitigation. \textbf{First}, cached paths may diverge from actual execution when runtime conditions differ from the profiled trace. Helios addresses this through lightweight \textit{control-flow guards} that verify jump targets before each transfer; upon mismatch, execution immediately falls back to the native interpreter. \textbf{Second}, adversaries may craft contracts that generate numerous cold paths to overwhelm the cache. Helios counters such path-explosion attacks through \textit{frequency-based filtering} that admits only statistically significant hot paths into the acceleration pipeline, ensuring attack-generated paths remain excluded due to insufficient execution counts.

In summary, this paper makes the following contributions:
\begin{itemize}[leftmargin=0pt, itemindent=2em, labelsep=0.5em]

\item We identify the \textit{Optimization Dilemma} on modern execution engines and propose \textbf{asynchronous lightweight tracing} that decouples trace generation from the critical path, addressing the overhead barrier without blocking execution.

\item We design \textbf{frame-level caching with frequency-based filtering} that exploits execution locality to transform ephemeral artifacts into reusable components while providing inherent resistance to path-explosion attacks.

\item We develop a \textbf{guarded register-based interpreter} that achieves acceleration through direct data access and bulk gas deduction, while runtime control-flow guards ensure semantic equivalence with the native engine.

\item We implement Helios on Revm and demonstrate its \textbf{architectural versatility}, achieving 6.60$\times$ median speedup in Replay Mode and 2$\times$ acceleration in Online Mode for real-time validation.

\end{itemize}

Taken together, Helios advances the state of the art along four dimensions. \textit{Safety}: hybrid execution preserves gas-semantic equivalence by construction, addressing a challenge that has limited JIT and superoptimization approaches. \textit{Efficiency}: asynchronous tracing resolves the optimization dilemma, while the guarded register-based interpreter achieves 6.60$\times$ median speedup on the already highly optimized Revm. \textit{Robustness}: control-flow guards and frequency-based filtering protect against path divergence and cache-flooding attacks. \textit{Versatility}: a dual-mode architecture unifies the acceleration landscape, serving both latency-sensitive validators and throughput-oriented archive nodes within a single framework.
