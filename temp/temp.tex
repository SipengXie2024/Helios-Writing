\section{Introduction}

Public blockchains supporting smart contracts, such as Ethereum and its Layer-2 rollups~\cite{ethereum,base,arbitrum,polygon,bsc}, fundamentally operate as replicated state machines. From a data management perspective, each node functions as a deterministic transaction processor handling two distinct workloads. These workloads comprise the real-time processing of incoming transactions and the re-execution of historical transactions to verify global state transitions. As throughput and contract complexity increase, execution becomes a primary scalability bottleneck for both scenarios.

Recent acceleration strategies face distinct limitations on modern execution engines~\cite{revm,evmone}. Just-In-Time compilation introduces security risks, such as JIT bombs, and causes gas accounting discrepancies~\cite{revmc,monad,evmjit,bnbjit,JITBomb}. Transaction-level speculative execution degrades performance on fast engines due to the \textit{Performance Paradox}~\cite{forerunner,seer}. In this phenomenon, the overhead of instrumentation, tracing, and artifact management frequently exceeds the latency of transaction execution itself. Similarly, operation-level concurrent execution incurs tracing or synchronization costs that frequently outweigh parallel gains~\cite{parallelEvm,evmTracer}.

Overcoming this paradox necessitates addressing three intertwined challenges. \textbf{First}, achieving net acceleration on sub-microsecond engines requires strictly decoupling heavy tasks, such as tracing and optimization, from the critical path. Synchronous overhead during transaction execution inevitably erodes optimization gains. \textbf{Second}, existing transaction-level approaches treat optimization artifacts as ephemeral. The challenge lies in architecting a persistent storage model that maximizes artifact reuse across diverse execution contexts, thereby moving beyond the limitations of single-use traces. \textbf{Third}, aggressive optimization strategies must avoid security vulnerabilities and ensure exact gas-semantic equivalence without relying on complex runtime compensation.

To assess whether these challenges can be addressed in practice, we analyze Ethereum mainnet workloads to identify high-leverage optimization opportunities. We observe pronounced \textit{frame-level path locality}, where a small fraction of unique paths accounts for most execution time. Furthermore, along these hot paths, expensive state-access operations are relatively rare, and most instructions behave like fixed-cost computation. These insights indicate that a path-driven accelerator can focus on reusable frame-level paths and on accelerating pure computation, while leaving dynamic operations to the native handling logic.

Guided by these observations, we propose Helios, a path-driven execution engine built on three architectural pillars. To minimize critical path overhead, Helios employs asynchronous stack-only tracing to offload analysis to background threads. These traces are transformed into graph artifacts with explicit data dependencies. These artifacts are then executed by a specialized register-based interpreter to eliminate redundant stack manipulations. To efficiently organize and utilize artifacts, Helios implements frame-level caching to enable a unified dual-mode design. This design includes a Replay Mode that maximizes throughput for historical transaction execution by reusing precomputed paths and an Online Mode that leverages path locality to speculatively accelerate hot paths for incoming transactions. Finally, to ensure safety, Helios optimizes only executed healthy paths and adopts a hybrid execution model. This model bulk-deducts static gas while delegating dynamic operations to the native host, guaranteeing gas consistency by construction.

In summary, this paper makes the following contributions:
\begin{itemize}[leftmargin=0pt, itemindent=2em, labelsep=0.5em]

\item We investigate the limitations of transaction-level speculation and operation-level concurrency on modern execution engines to formulate the \textit{Performance Paradox}, where auxiliary overheads negate optimization gains. We further identify frame-level path locality and the separation of static and dynamic costs as key levers to resolve this paradox.

\item We propose a novel architecture that decouples optimization from critical execution paths via asynchronous lightweight tracing and maximizes artifact reuse through frame-level caching. This approach ensures minimal instrumentation overhead and high cache hit rates.

\item We develop the high-performance Helios Engine utilizing a register-based interpreter and bulk gas deduction to minimize execution overhead. It ensures intrinsic gas consistency through a hybrid model that strictly separates static optimizations from dynamic costs. This engine serves as the versatile runtime powering both deterministic replay and speculative execution within our unified framework.

\item We implement a prototype of Helios on Revm and evaluate it using Ethereum mainnet workloads. The results demonstrate a median speedup of 6.60$\times$ over the native baseline on historical workloads while providing effective acceleration for incoming transactions.

\end{itemize}